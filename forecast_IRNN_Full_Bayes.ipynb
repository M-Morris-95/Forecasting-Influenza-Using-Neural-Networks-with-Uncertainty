{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lib.Metrics as Metrics\n",
    "from lib.models.IRNN_Full_Bayes import IRNN_Full_Bayes\n",
    "from lib.models.IRNN import IRNN\n",
    "from lib.train_functions import fit\n",
    "from lib.utils import *\n",
    "from lib.regional_data_builder import DataConstructor\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'US'\n",
    "n_queries = 90\n",
    "n_regions = 1\n",
    "\n",
    "for test_season in [2015, 2016, 2017, 2018]:\n",
    "    batch_size = 32\n",
    "    window_size = 28\n",
    "    _data = DataConstructor(test_season=test_season, region = region, window_size=window_size, n_queries=n_queries, gamma=28)\n",
    "    x_train, y_train, x_test, y_test, scaler = _data()\n",
    "\n",
    "    x_train = tf.cast(x_train, tf.float32)\n",
    "    y_train = tf.cast(y_train, tf.float32)\n",
    "    x_test = tf.cast(x_test, tf.float32)\n",
    "    y_test = tf.cast(y_test, tf.float32)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "    n_op = y_test.shape[-1]\n",
    "\n",
    "    gamma = 28\n",
    "    epochs= 30\n",
    "    kl_power= -2.857091693154802\n",
    "    lr_power= -3.7364141761644545\n",
    "    op_scale_pwr= -0.27139484469983133\n",
    "    p_scale_pwr= -1.827071638197097\n",
    "    q_scale_pwr= -1.2461978663286395\n",
    "    rnn_units= 108\n",
    "    lag = 14\n",
    "    epochs= 1\n",
    "    n_samples = 3\n",
    "    prediction_steps = 5\n",
    "\n",
    "\n",
    "    _model = IRNN_Full_Bayes(kl_power=kl_power, \n",
    "                        n_op=n_op,\n",
    "                        op_scale_pwr=op_scale_pwr,\n",
    "                        p_scale_pwr=p_scale_pwr,\n",
    "                        q_scale_pwr=q_scale_pwr,\n",
    "                        rnn_units = rnn_units, \n",
    "                        gamma=gamma,       \n",
    "                        window_size=window_size, \n",
    "                        lag = lag,\n",
    "                        n_samples=prediction_steps,\n",
    "                        n_regions = n_regions,\n",
    "                        use_bn = True\n",
    "                        )\n",
    "\n",
    "    def loss_fn(y, p_y):\n",
    "        return -p_y.log_prob(y)\n",
    "\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=10**lr_power)\n",
    "    \n",
    "    pred = _model(x_test)\n",
    "\n",
    "    _model, history = fit(_model, \n",
    "                        train_dataset,\n",
    "                        optimizer=optimizer, \n",
    "                        epochs = epochs, \n",
    "                        loss_fn = loss_fn,  \n",
    "                        prediction_steps = prediction_steps,\n",
    "                        reset_pos=2000\n",
    "                        )\n",
    "    \n",
    "    file = f'Weights/{test_season}{region}_weights.tf'\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        \n",
    "    _model.save_weights(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_37404\\812572060.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  scaler = scaler[0]\n"
     ]
    }
   ],
   "source": [
    "region = 'US'\n",
    "n_queries = 90\n",
    "n_regions = 1\n",
    "\n",
    "predictions = {}\n",
    "for test_season in [2016]:\n",
    "    batch_size = 32\n",
    "    window_size = 28\n",
    "    _data = DataConstructor(test_season=test_season, region = region, window_size=window_size, n_queries=n_queries, gamma=28)\n",
    "    x_train, y_train, x_test, y_test, scaler = _data()\n",
    "\n",
    "    x_train = tf.cast(x_train, tf.float32)\n",
    "    y_train = tf.cast(y_train, tf.float32)\n",
    "    x_test = tf.cast(x_test, tf.float32)\n",
    "    y_test = tf.cast(y_test, tf.float32)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "    n_op = y_test.shape[-1]\n",
    "\n",
    "    gamma = 28\n",
    "    epochs= 30\n",
    "    kl_power= -2.857091693154802\n",
    "    lr_power= -3.7364141761644545\n",
    "    op_scale_pwr= -0.27139484469983133\n",
    "    p_scale_pwr= -1.827071638197097\n",
    "    q_scale_pwr= -1.2461978663286395\n",
    "    rnn_units= 108\n",
    "    lag = 14\n",
    "\n",
    "    n_samples = 3\n",
    "    prediction_steps = 5\n",
    "    n_regions = 49\n",
    "\n",
    "\n",
    "    file = f'Weights/{test_season}{region}_weights.tf'\n",
    "\n",
    "    loaded_model = IRNN_Full_Bayes(kl_power=kl_power, \n",
    "                            n_op=n_op,\n",
    "                            op_scale_pwr=op_scale_pwr,\n",
    "                            p_scale_pwr=p_scale_pwr,\n",
    "                            q_scale_pwr=q_scale_pwr,\n",
    "                            rnn_units = rnn_units, \n",
    "                            gamma=gamma,       \n",
    "                            window_size=window_size, \n",
    "                            lag = lag,\n",
    "                            n_samples=prediction_steps,\n",
    "                            use_bn = True\n",
    "                            )\n",
    "    \n",
    "    try:\n",
    "        scaler = scaler[np.newaxis, np.newaxis, :]\n",
    "    except:\n",
    "        scaler = scaler[0]\n",
    "        \n",
    "    loaded_model.load_weights(file)\n",
    "\n",
    "    y_pred = loaded_model.predict(x_test, 128, verbose=True)\n",
    "    std = (y_pred[0]+y_pred[1])[..., -n_regions:] * scaler - y_pred[0][..., -n_regions:] * scaler\n",
    "    mean = y_pred[0][..., -n_regions:] * scaler\n",
    "    y_te = y_test[..., -n_regions:]*scaler\n",
    "\n",
    "    predictions[test_season] = {'true':y_te,\n",
    "                            'mean':mean,\n",
    "                            'std':std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\OneDrive\\Documents\\GitHub\\Forecasting-Influenza-Using-Neural-Networks-with-Uncertainty\\lib\\Metrics.py:194: RuntimeWarning: divide by zero encountered in log\n",
      "  mbl = np.log((dist.cdf(true + 0.6) - dist.cdf(true - 0.5)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.767802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.769358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.743110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.717331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2016\n",
       "7   0.767802\n",
       "14  0.769358\n",
       "21  0.743110\n",
       "28  0.717331"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.344572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.375264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.536412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.668337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2016\n",
       "7   0.344572\n",
       "14  0.375264\n",
       "21  0.536412\n",
       "28  0.668337"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_seasons = [2016]\n",
    "skills = pd.DataFrame(index = [7,14,21,28], columns = test_seasons, dtype=float)\n",
    "nlls = pd.DataFrame(index = [7,14,21,28], columns = test_seasons, dtype=float)\n",
    "for g in [6,13,20,27]:\n",
    "    for season in test_seasons:\n",
    "        try:\n",
    "            pred = predictions[season]\n",
    "            skills.loc[g+1, season] = np.exp(np.mean(Metrics.mb_log(pred['true'][:, g, :], pred['mean'][:, g, :], pred['std'][:, g, :]))).astype(float)\n",
    "            nlls.loc[g+1, season] = Metrics.nll(pred['true'][:, g-1, -1], pred['mean'][:, g-1, -1], pred['std'][:, g-1, -1])\n",
    "        except:\n",
    "            pass\n",
    "display(skills)\n",
    "display(nlls)\n",
    "\n",
    "for test_season in test_seasons:\n",
    "    pred = predictions[test_season]\n",
    "    for num, g in zip([1,2,3,4], [6,13,20,27]):\n",
    "        plt.subplot(2,2,num)\n",
    "        plt.plot(pred['true'][:, g, -1], color='black')\n",
    "        plt.plot(pred['mean'][:, g, -1], color='red')\n",
    "        plt.fill_between(np.arange(pred['true'].shape[0]), (pred['mean']-pred['std'])[:, g, -1], (pred['mean']+pred['std'])[:, g, -1], color='red', linewidth = 0, alpha = 0.3)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

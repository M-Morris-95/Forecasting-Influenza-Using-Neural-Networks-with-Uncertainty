{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability.python.distributions import kullback_leibler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import interpolate\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import tqdm\n",
    "\n",
    "from lib.Metrics import Metrics\n",
    "from lib.IRNN_Bayes import IRNN_Bayes\n",
    "from lib.IRNN import IRNN\n",
    "from lib.train_functions import fit\n",
    "from lib.regional_data_builder import DataConstructor\n",
    "from lib.utils import *\n",
    "\n",
    "tfd = tfp.distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Class to evaluate a set of hyper parameters. \n",
    "# Using a class allows the __call__ function to be used for different models with different configurations\n",
    "# class is used wih bayesian optimization to find the best hyper parameters\n",
    "class Eval_Fn:\n",
    "    def __init__(self, root='', model=None, country='US', n_folds = 5, season = 2017, gamma=28, plot=True, verbose=True, n_queries=49, min_score=-25, **kwargs):\n",
    "        self.model = model  \n",
    "        self.n_folds = n_folds      # number of folda (k fold cross validation)\n",
    "        self.season = season\n",
    "        self.gamma = gamma      \n",
    "        self.plot = plot            # save plots validation set forecasts  \n",
    "        self.verbose = verbose      # print during training\n",
    "        self.min_score = min_score  # score to give hyper paremeters if they break and get -infinity\n",
    "        self.root = root            # save directory\n",
    "        self.country = country\n",
    "        # get data for training, text data unused.\n",
    "        \n",
    "        self._data = DataConstructor(test_season = season, country=country, full_year=False, gamma = 28, window_size = 54, teacher_forcing=True, n_queries = 99)\n",
    "        self.x_train, self.y_train, self.x_test, self.y_test = self._data()\n",
    "\n",
    "#         self.x_train, self.y_train, self.x_test, self.y_test = self._data(self.model.model_type, self.model.forecast_type, self.model.query_forecast)\n",
    "        self.x_train = tf.cast(self.x_train, tf.float32)\n",
    "        self.y_train = tf.cast(self.y_train, tf.float32)\n",
    "        self.x_test = tf.cast(self.x_test, tf.float32)\n",
    "        self.y_test = tf.cast(self.y_test, tf.float32)\n",
    "\n",
    "    def __call__(self, batch_size = 32, **kwargs):\n",
    "        tf.keras.backend.clear_session()\n",
    "        score = {}\n",
    "        plt.clf()\n",
    "\n",
    "        for fold in range(self.n_folds):\n",
    "            try:\n",
    "                if 'n_op' in kwargs:\n",
    "                    kwargs['n_op'] = int(kwargs['n_op'])\n",
    "                # split data into train and validation folds\n",
    "                if isinstance(self.x_train, list):\n",
    "                    x_val = [d[-(365*(fold+1)): -(365*(fold)+1)] for d in self.x_train]\n",
    "                    x_tr = [d[:-(365*(fold+1))] for d in self.x_train]\n",
    "\n",
    "                else:\n",
    "                    x_val = self.x_train[-(365*(fold+1)): -(365*(fold)+1)]\n",
    "                    x_tr = self.x_train[:-(365*(fold+1))]\n",
    "\n",
    "                y_val = self.y_train[-(365*(fold+1)): -(365*(fold)+1)]\n",
    "                y_tr = self.y_train[:-(365*(fold+1))]\n",
    "\n",
    "                val_dates = self._data.train_dates[-365*(fold+1): -(365*fold)-1]\n",
    "                train_dates = self._data.train_dates[:-365*(fold+1)]\n",
    "\n",
    "                x_val = x_val[:,:,-kwargs['n_op']:]\n",
    "                y_val = y_val[:,:,-kwargs['n_op']:].numpy()\n",
    "\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((x_tr[:,:,-kwargs['n_op']:], y_tr[:,:,-kwargs['n_op']:]))\n",
    "                train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "\n",
    "                _model = self.model(**kwargs)\n",
    "\n",
    "                # define loss, epochs learning rate\n",
    "                if _model.loss == 'NLL':\n",
    "                    def loss(y, p_y):\n",
    "                        return -p_y.log_prob(y)\n",
    "                if _model.loss == 'MSE':\n",
    "                    loss = tf.keras.losses.mean_squared_error\n",
    "\n",
    "                if 'epochs' in kwargs:\n",
    "                    epochs = int(kwargs['epochs'])\n",
    "                else:\n",
    "                    epochs = self.epochs\n",
    "\n",
    "                if 'lr_power' in kwargs:\n",
    "                    lr = np.power(10, kwargs['lr_power'])\n",
    "                else:\n",
    "                    lr = 1e-3\n",
    "\n",
    "                def loss_fn(y, p_y):\n",
    "                    return -p_y.log_prob(y)\n",
    "\n",
    "                optimizer = tf.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "                _model(x_val)\n",
    "                prediction_steps = 3\n",
    "                _model, history = fit(_model, \n",
    "                        train_dataset,\n",
    "                        optimizer=optimizer, \n",
    "                        epochs = epochs, \n",
    "                        loss_fn = loss_fn,  \n",
    "                        prediction_steps = prediction_steps,\n",
    "                        speedy_training=False\n",
    "                        )\n",
    "\n",
    "                predictions = _model.predict(x_val, 25, verbose=True)\n",
    "\n",
    "                df = convert_to_df(predictions, y_val, val_dates + dt.timedelta(days = self.gamma), self._data, type=_model.forecast_type)\n",
    "\n",
    "                # get score for fold, 2 options depending on whether the forecast is a list (IRNN) or a single prediction\n",
    "                try:\n",
    "                    score[fold] = Metrics.nll(df[self.gamma])\n",
    "                except:\n",
    "                    score[fold] = np.sum(np.asarray([Metrics.nll(d) for d in df.values()]))\n",
    "\n",
    "                # can be useful to plot the validation curves to check things are working \n",
    "                if self.plot:\n",
    "                    for idx, d in enumerate(df.values()):\n",
    "                        plt.subplot(len(df.keys()), 1, idx+1)\n",
    "                        plt.plot(d.index, d['True'], color='black')\n",
    "                        plt.plot(d.index, d['Pred'], color='red')\n",
    "                        plt.fill_between(d.index, d['Pred']+d['Std'], d['Pred']-d['Std'], color='red', alpha=0.3)\n",
    "            except Exception as e:\n",
    "                score[fold] = -self.min_score\n",
    "                print(e)\n",
    "\n",
    "        if self.plot:\n",
    "            if not os.path.exists(self.root):\n",
    "                os.mkdir(self.root)\n",
    "            figs = os.listdir(self.root)\n",
    "            nums=[-1]\n",
    "            for f in figs:\n",
    "                if 'fig' in f:\n",
    "                    nums.append(int(f.split('_')[1].split('.')[0]))\n",
    "\n",
    "            plt.savefig(self.root+'fig_'+str(max(nums)+1)+'.pdf')\n",
    "\n",
    "        try:\n",
    "            # NLL can be give nan values, try to prevent this breaking things\n",
    "            if np.isfinite(-sum(score.values())):\n",
    "                return -sum(score.values())\n",
    "            else:\n",
    "                return self.min_score\n",
    "        except:\n",
    "            return self.min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Eval_Fn at 0x2d076275f10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = Eval_Fn\n",
    "eval(gamma = 28,\n",
    "    epochs= 30,\n",
    "    kl_power= -2.857091693154802,\n",
    "    lr_power= -3.7364141761644545,\n",
    "    n_op= 93,\n",
    "    op_scale_pwr= -0.27139484469983133,\n",
    "    p_scale_pwr= -1.827071638197097,\n",
    "    q_scale_pwr= -1.2461978663286395,\n",
    "    rnn_units= 108\n",
    "    )\n",
    "eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {'rnn_units':(25,125),        # units in rnn layer\n",
    "               'n_queries':(20,100),        # number of queries\n",
    "               'kl_power':(-3,0),           # KL annealing term = 10^kl_power\n",
    "               'op_scale':(0.01, 0.1),      # scaling factor for output\n",
    "               'prior_scale':(1e-4, 1e-2),  # prior stddev\n",
    "               'epochs':(10,100),           # epochs to train for\n",
    "               'lr_power':(-4, -2),         # learning rate = 10^lr_power\n",
    "               'q_scale':(0.001, 0.1)       # posterior scaling factor\n",
    "               }\n",
    "\n",
    "num = 3\n",
    "df = pd.DataFrame(columns = ['rnn_units', 'n_op', 'kl_power', 'op_scale', 'prior_scale', 'epochs', 'lr_power', 'q_scale'])\n",
    "for i in np.linspace(25, 125, num).astype(int):\n",
    "    for j in np.linspace(70, 70, 1).astype(int):\n",
    "        for k in np.linspace(-3, 0, num):\n",
    "            for l in np.linspace(0.01, 0.1, num):\n",
    "                for m in np.linspace(1e-4, 1e-2, num):\n",
    "                    for n in np.linspace(10, 100, num):\n",
    "                        for o in np.linspace(-3, -3, num):\n",
    "                            for p in np.linspace(0.001, 0.1, num):\n",
    "                                df = df.append(pd.DataFrame(columns = df.columns, data = np.asarray([[i,j,k,l,m,n,o,p]])))\n",
    "df['started'] = np.zeros(df.shape[0])\n",
    "df['validation_score'] = np.zeros(df.shape[0])\n",
    "df.to_csv('validation_scores.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(pd.DataFrame(columns = df.columns, data = np.asarray([[i,j,k,l,m,n,o,p]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_iter =250\n",
    "model = IRNN_Bayes\n",
    "gamma = 28\n",
    "root = 'Results/IRNN_Bayes/'\n",
    "n_folds = 2\n",
    "eval = Eval_Fn(model=IRNN_Bayes, root = root, gamma=gamma, plot=False, n_folds=n_folds, verbose=False)\n",
    "eval(gamma = 28,\n",
    "        epochs= 30,\n",
    "        kl_power= -2.857091693154802,\n",
    "        lr_power= -3.7364141761644545,\n",
    "        n_op= 93,\n",
    "        op_scale_pwr= -0.27139484469983133,\n",
    "        p_scale_pwr= -1.827071638197097,\n",
    "        q_scale_pwr= -1.2461978663286395,\n",
    "        rnn_units= 108\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRNN_Bayes.pbounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Results/IRNN_Bayes/optimiser_results.json'\n",
      "failed to register previous steps\n",
      "|   iter    |  target   |  epochs   | kl_power  | lr_power  |   n_op    | op_sca... | p_scal... | q_scal... | rnn_units |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "WARNING:tensorflow:From /home/mimorris/anaconda3/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.\n",
      "Instructions for updating:\n",
      "Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/142 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mimorris/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 142/142 [01:51<00:00,  1.28batch/s, kl=6.02e+3, nll=354]    \n",
      "Epoch 2: 100%|██████████| 142/142 [00:08<00:00, 16.12batch/s, kl=601, nll=291]   \n",
      "Epoch 3: 100%|██████████| 142/142 [00:08<00:00, 16.01batch/s, kl=207, nll=287]\n",
      "Epoch 4: 100%|██████████| 142/142 [00:08<00:00, 16.00batch/s, kl=154, nll=270]\n",
      "Epoch 5: 100%|██████████| 142/142 [00:08<00:00, 16.04batch/s, kl=132, nll=267]\n",
      "Epoch 6: 100%|██████████| 142/142 [00:08<00:00, 15.88batch/s, kl=123, nll=258]\n",
      "Epoch 7: 100%|██████████| 142/142 [00:08<00:00, 16.13batch/s, kl=117, nll=251]\n",
      "Epoch 8: 100%|██████████| 142/142 [00:08<00:00, 16.02batch/s, kl=108, nll=243]\n",
      "Epoch 9: 100%|██████████| 142/142 [00:08<00:00, 16.20batch/s, kl=106, nll=229]\n",
      "Epoch 10: 100%|██████████| 142/142 [00:08<00:00, 16.11batch/s, kl=103, nll=213]\n",
      "Epoch 11: 100%|██████████| 142/142 [00:08<00:00, 16.09batch/s, kl=120, nll=120]\n",
      "Epoch 12: 100%|██████████| 142/142 [00:08<00:00, 16.01batch/s, kl=103, nll=47]  \n",
      "Epoch 13: 100%|██████████| 142/142 [00:08<00:00, 15.86batch/s, kl=86.8, nll=46.5]\n",
      "Epoch 14: 100%|██████████| 142/142 [00:08<00:00, 16.01batch/s, kl=77.6, nll=23.2]\n",
      "Epoch 15: 100%|██████████| 142/142 [00:08<00:00, 16.15batch/s, kl=66.1, nll=26.7]\n",
      "Epoch 16: 100%|██████████| 142/142 [00:08<00:00, 16.03batch/s, kl=67.2, nll=39.8]\n",
      "Epoch 17: 100%|██████████| 142/142 [00:08<00:00, 16.26batch/s, kl=60.5, nll=26.4]\n",
      "Epoch 18: 100%|██████████| 142/142 [00:08<00:00, 16.20batch/s, kl=57.4, nll=17.2]\n",
      "Epoch 19: 100%|██████████| 142/142 [00:08<00:00, 16.14batch/s, kl=51.1, nll=15]  \n",
      "Epoch 20: 100%|██████████| 142/142 [00:08<00:00, 16.18batch/s, kl=56, nll=27.1]  \n",
      "Epoch 21: 100%|██████████| 142/142 [00:08<00:00, 16.15batch/s, kl=48.4, nll=21.8]\n",
      "Epoch 22: 100%|██████████| 142/142 [00:08<00:00, 16.17batch/s, kl=43.7, nll=20.9]\n",
      "Epoch 23: 100%|██████████| 142/142 [00:08<00:00, 16.06batch/s, kl=56.6, nll=43.6]\n",
      "Epoch 24: 100%|██████████| 142/142 [00:08<00:00, 16.14batch/s, kl=50.8, nll=14.4]\n",
      "Epoch 25: 100%|██████████| 142/142 [00:08<00:00, 16.01batch/s, kl=39.6, nll=15.1]\n",
      "Epoch 26: 100%|██████████| 142/142 [00:08<00:00, 16.07batch/s, kl=38.4, nll=11.7]\n",
      "Epoch 27: 100%|██████████| 142/142 [00:08<00:00, 16.16batch/s, kl=45, nll=35.4]  \n",
      "Epoch 28: 100%|██████████| 142/142 [00:08<00:00, 15.90batch/s, kl=43.6, nll=15.7]\n",
      "Epoch 29: 100%|██████████| 142/142 [00:08<00:00, 16.06batch/s, kl=34.9, nll=13]  \n",
      "Epoch 30: 100%|██████████| 142/142 [00:08<00:00, 16.29batch/s, kl=39.9, nll=33.5]\n",
      "Epoch 31: 100%|██████████| 142/142 [00:08<00:00, 16.09batch/s, kl=37.1, nll=10.1]\n",
      "Epoch 32: 100%|██████████| 142/142 [00:08<00:00, 16.08batch/s, kl=32.2, nll=17.5]\n",
      "Epoch 33: 100%|██████████| 142/142 [00:08<00:00, 16.28batch/s, kl=32.8, nll=16.9]\n",
      "Epoch 34: 100%|██████████| 142/142 [00:08<00:00, 16.27batch/s, kl=30.5, nll=9.25]\n",
      "Epoch 35: 100%|██████████| 142/142 [00:08<00:00, 16.11batch/s, kl=27.1, nll=9.98]\n",
      "Epoch 36: 100%|██████████| 142/142 [00:08<00:00, 15.99batch/s, kl=29, nll=19.7]  \n",
      "Epoch 37: 100%|██████████| 142/142 [00:08<00:00, 16.07batch/s, kl=27.9, nll=9.5] \n",
      "Epoch 38: 100%|██████████| 142/142 [00:08<00:00, 16.12batch/s, kl=28.4, nll=18.5]\n",
      "Epoch 39: 100%|██████████| 142/142 [00:08<00:00, 16.13batch/s, kl=28.3, nll=11]  \n",
      "Epoch 40: 100%|██████████| 142/142 [00:08<00:00, 16.02batch/s, kl=25, nll=9.76]  \n",
      "Epoch 41: 100%|██████████| 142/142 [00:08<00:00, 16.02batch/s, kl=25.5, nll=12.5]\n",
      "Epoch 42: 100%|██████████| 142/142 [00:08<00:00, 15.99batch/s, kl=24.7, nll=11]  \n",
      "Epoch 43: 100%|██████████| 142/142 [00:08<00:00, 16.02batch/s, kl=28.1, nll=19.6]\n",
      "Epoch 44: 100%|██████████| 142/142 [00:08<00:00, 16.07batch/s, kl=25.4, nll=14]  \n",
      "Epoch 45: 100%|██████████| 142/142 [00:08<00:00, 16.24batch/s, kl=25.6, nll=12.2]\n",
      "Epoch 46: 100%|██████████| 142/142 [00:08<00:00, 16.14batch/s, kl=22.9, nll=6.49]\n",
      "Epoch 47: 100%|██████████| 142/142 [00:08<00:00, 16.05batch/s, kl=21.1, nll=9.69]\n",
      "Epoch 48: 100%|██████████| 142/142 [00:08<00:00, 16.22batch/s, kl=23.6, nll=13.2]\n",
      "Epoch 49: 100%|██████████| 142/142 [00:08<00:00, 16.00batch/s, kl=23.8, nll=18.3]\n",
      "Epoch 50: 100%|██████████| 142/142 [00:08<00:00, 16.14batch/s, kl=21.6, nll=6.88]\n",
      "Epoch 51: 100%|██████████| 142/142 [00:08<00:00, 16.06batch/s, kl=19.3, nll=7.9] \n",
      "Epoch 52: 100%|██████████| 142/142 [00:08<00:00, 16.04batch/s, kl=23.3, nll=18.9]\n",
      "Epoch 53: 100%|██████████| 142/142 [00:08<00:00, 16.20batch/s, kl=23.7, nll=17.2]\n",
      "Epoch 54: 100%|██████████| 142/142 [00:08<00:00, 16.16batch/s, kl=19.6, nll=6.09]\n",
      "Epoch 55: 100%|██████████| 142/142 [00:08<00:00, 16.11batch/s, kl=20.3, nll=9.83]\n",
      "Epoch 56: 100%|██████████| 142/142 [00:08<00:00, 15.85batch/s, kl=17.9, nll=7.44]\n",
      "Epoch 57: 100%|██████████| 142/142 [00:08<00:00, 15.84batch/s, kl=17.1, nll=9.25]\n",
      "Epoch 58: 100%|██████████| 142/142 [00:08<00:00, 16.12batch/s, kl=17.1, nll=12.6]\n",
      "Epoch 59: 100%|██████████| 142/142 [00:08<00:00, 16.26batch/s, kl=19.4, nll=12.4]\n",
      "Epoch 60: 100%|██████████| 142/142 [00:08<00:00, 16.17batch/s, kl=17.3, nll=7.85]\n",
      "Epoch 61: 100%|██████████| 142/142 [00:08<00:00, 15.96batch/s, kl=19.6, nll=17.3]\n",
      "Epoch 62: 100%|██████████| 142/142 [00:08<00:00, 16.11batch/s, kl=16.1, nll=5.7] \n",
      "Epoch 63: 100%|██████████| 142/142 [00:08<00:00, 16.11batch/s, kl=15.7, nll=12.1]\n",
      "Epoch 64: 100%|██████████| 142/142 [00:08<00:00, 16.13batch/s, kl=17.1, nll=11.3]\n",
      "Epoch 65: 100%|██████████| 142/142 [00:08<00:00, 16.22batch/s, kl=21, nll=12.6]  \n",
      "Epoch 66: 100%|██████████| 142/142 [00:08<00:00, 16.04batch/s, kl=17, nll=9.99]  \n",
      "Epoch 67: 100%|██████████| 142/142 [00:08<00:00, 16.09batch/s, kl=15.3, nll=5.12]\n",
      "Epoch 68: 100%|██████████| 142/142 [00:08<00:00, 16.02batch/s, kl=15.9, nll=11.9]\n",
      "Epoch 69: 100%|██████████| 142/142 [00:08<00:00, 16.10batch/s, kl=19.3, nll=17.3]\n",
      "Epoch 70: 100%|██████████| 142/142 [00:08<00:00, 16.06batch/s, kl=20.3, nll=11.5]\n",
      "Epoch 71: 100%|██████████| 142/142 [00:08<00:00, 15.80batch/s, kl=15.3, nll=5]   \n",
      "Epoch 72: 100%|██████████| 142/142 [00:08<00:00, 15.89batch/s, kl=13.9, nll=8.33] \n",
      "Epoch 73: 100%|██████████| 142/142 [00:08<00:00, 16.12batch/s, kl=13.8, nll=7.33]\n",
      "Epoch 74: 100%|██████████| 142/142 [00:08<00:00, 16.24batch/s, kl=18.3, nll=20.2]\n",
      "Epoch 75: 100%|██████████| 142/142 [00:08<00:00, 16.11batch/s, kl=16.9, nll=9.02]\n",
      "Epoch 76: 100%|██████████| 142/142 [00:08<00:00, 16.22batch/s, kl=13.8, nll=6.48]\n",
      "Epoch 77: 100%|██████████| 142/142 [00:08<00:00, 16.18batch/s, kl=13.4, nll=8.12]\n",
      "Epoch 78: 100%|██████████| 142/142 [00:08<00:00, 16.03batch/s, kl=13.2, nll=11]  \n",
      "Epoch 79: 100%|██████████| 142/142 [00:08<00:00, 16.20batch/s, kl=12.3, nll=3.41]\n",
      "Epoch 80: 100%|██████████| 142/142 [00:08<00:00, 16.20batch/s, kl=13.6, nll=10.6]\n",
      "Epoch 81: 100%|██████████| 142/142 [00:08<00:00, 16.27batch/s, kl=11.7, nll=3.73]\n",
      "Epoch 82: 100%|██████████| 142/142 [00:08<00:00, 16.05batch/s, kl=11.3, nll=8.07]\n",
      "Epoch 83: 100%|██████████| 142/142 [00:08<00:00, 16.12batch/s, kl=14, nll=14.6]  \n",
      "Epoch 84: 100%|██████████| 142/142 [00:08<00:00, 16.09batch/s, kl=12.6, nll=5.85]\n",
      "Epoch 85: 100%|██████████| 142/142 [00:08<00:00, 16.16batch/s, kl=11.4, nll=5.56]\n",
      "Epoch 86: 100%|██████████| 142/142 [00:08<00:00, 16.19batch/s, kl=14.3, nll=14.1]\n",
      "Epoch 87: 100%|██████████| 142/142 [00:08<00:00, 15.98batch/s, kl=14.6, nll=4.84]\n",
      "Epoch 88: 100%|██████████| 142/142 [00:08<00:00, 16.10batch/s, kl=12.6, nll=6.22]\n",
      "Epoch 89: 100%|██████████| 142/142 [00:08<00:00, 16.25batch/s, kl=11.5, nll=10]  \n",
      "Epoch 90: 100%|██████████| 142/142 [00:08<00:00, 16.14batch/s, kl=12.9, nll=10.7]\n",
      "Epoch 91: 100%|██████████| 142/142 [00:08<00:00, 16.04batch/s, kl=11.4, nll=3.65]\n",
      "Epoch 92: 100%|██████████| 142/142 [00:08<00:00, 16.02batch/s, kl=11.8, nll=11.6]\n",
      "Epoch 93: 100%|██████████| 142/142 [00:08<00:00, 16.17batch/s, kl=14, nll=6.21]  \n",
      "Epoch 94: 100%|██████████| 142/142 [00:08<00:00, 16.08batch/s, kl=10.7, nll=5.55]\n",
      "Epoch 95: 100%|██████████| 142/142 [00:08<00:00, 15.98batch/s, kl=11.1, nll=5.45]\n",
      "Epoch 96: 100%|██████████| 142/142 [00:08<00:00, 15.97batch/s, kl=14.4, nll=8.3] \n",
      "Epoch 97: 100%|██████████| 142/142 [00:08<00:00, 16.18batch/s, kl=10.9, nll=3.79]\n",
      "Epoch 98: 100%|██████████| 142/142 [00:08<00:00, 16.16batch/s, kl=10.3, nll=5.65] \n",
      "Epoch 99: 100%|██████████| 142/142 [00:08<00:00, 16.17batch/s, kl=13.7, nll=14.9]\n",
      "Epoch 100: 100%|██████████| 142/142 [00:08<00:00, 16.05batch/s, kl=13.1, nll=7.82]\n",
      "Epoch 1: 100%|██████████| 130/130 [01:49<00:00,  1.19batch/s, kl=6.29e+3, nll=349]\n",
      "Epoch 2: 100%|██████████| 130/130 [00:08<00:00, 15.61batch/s, kl=671, nll=298]   \n",
      "Epoch 3: 100%|██████████| 130/130 [00:08<00:00, 15.83batch/s, kl=220, nll=294]\n",
      "Epoch 4: 100%|██████████| 130/130 [00:08<00:00, 15.75batch/s, kl=152, nll=288]\n",
      "Epoch 5: 100%|██████████| 130/130 [00:08<00:00, 15.57batch/s, kl=135, nll=277]\n",
      "Epoch 6: 100%|██████████| 130/130 [00:08<00:00, 15.52batch/s, kl=126, nll=272]\n",
      "Epoch 7: 100%|██████████| 130/130 [00:08<00:00, 15.52batch/s, kl=120, nll=260]\n",
      "Epoch 8: 100%|██████████| 130/130 [00:08<00:00, 15.66batch/s, kl=116, nll=252]\n",
      "Epoch 9: 100%|██████████| 130/130 [00:08<00:00, 15.78batch/s, kl=111, nll=240]\n",
      "Epoch 10: 100%|██████████| 130/130 [00:08<00:00, 15.69batch/s, kl=108, nll=227]\n",
      "Epoch 11: 100%|██████████| 130/130 [00:08<00:00, 15.62batch/s, kl=122, nll=171]\n",
      "Epoch 12: 100%|██████████| 130/130 [00:08<00:00, 15.55batch/s, kl=122, nll=57]  \n",
      "Epoch 13: 100%|██████████| 130/130 [00:08<00:00, 15.62batch/s, kl=93.4, nll=34.6]\n",
      "Epoch 14: 100%|██████████| 130/130 [00:08<00:00, 15.54batch/s, kl=82.7, nll=33.6]\n",
      "Epoch 15: 100%|██████████| 130/130 [00:08<00:00, 15.71batch/s, kl=69.8, nll=21.6]\n",
      "Epoch 16: 100%|██████████| 130/130 [00:08<00:00, 15.67batch/s, kl=66.6, nll=27.6]\n",
      "Epoch 17: 100%|██████████| 130/130 [00:08<00:00, 15.48batch/s, kl=64.5, nll=26.2]\n",
      "Epoch 18: 100%|██████████| 130/130 [00:08<00:00, 15.41batch/s, kl=57.7, nll=17.6]\n",
      "Epoch 19: 100%|██████████| 130/130 [00:08<00:00, 15.52batch/s, kl=57.2, nll=23.3]\n",
      "Epoch 20: 100%|██████████| 130/130 [00:08<00:00, 15.50batch/s, kl=52.8, nll=20.1]\n",
      "Epoch 21: 100%|██████████| 130/130 [00:08<00:00, 15.49batch/s, kl=54.7, nll=26.1]\n",
      "Epoch 22: 100%|██████████| 130/130 [00:08<00:00, 15.52batch/s, kl=51.3, nll=31.3]\n",
      "Epoch 23: 100%|██████████| 130/130 [00:08<00:00, 15.54batch/s, kl=52.3, nll=18.3]\n",
      "Epoch 24: 100%|██████████| 130/130 [00:08<00:00, 15.70batch/s, kl=45.2, nll=17.3]\n",
      "Epoch 25: 100%|██████████| 130/130 [00:08<00:00, 15.63batch/s, kl=43.8, nll=22.6]\n",
      "Epoch 26: 100%|██████████| 130/130 [00:08<00:00, 15.59batch/s, kl=44.8, nll=17.6]\n",
      "Epoch 27: 100%|██████████| 130/130 [00:08<00:00, 15.63batch/s, kl=40.4, nll=17.1]\n",
      "Epoch 28: 100%|██████████| 130/130 [00:08<00:00, 15.66batch/s, kl=40.2, nll=22.9]\n",
      "Epoch 29: 100%|██████████| 130/130 [00:08<00:00, 15.63batch/s, kl=38.2, nll=16.4]\n",
      "Epoch 30: 100%|██████████| 130/130 [00:08<00:00, 15.47batch/s, kl=37.1, nll=16]  \n",
      "Epoch 31: 100%|██████████| 130/130 [00:08<00:00, 15.44batch/s, kl=37.1, nll=21.5]\n",
      "Epoch 32: 100%|██████████| 130/130 [00:08<00:00, 15.42batch/s, kl=35.1, nll=8.55]\n",
      "Epoch 33: 100%|██████████| 130/130 [00:08<00:00, 15.53batch/s, kl=36.4, nll=26.5]\n",
      "Epoch 34: 100%|██████████| 130/130 [00:08<00:00, 15.63batch/s, kl=37.2, nll=15.9]\n",
      "Epoch 35: 100%|██████████| 130/130 [00:08<00:00, 15.61batch/s, kl=35.6, nll=16.6]\n",
      "Epoch 36: 100%|██████████| 130/130 [00:08<00:00, 15.61batch/s, kl=30.2, nll=11.9]\n",
      "Epoch 37: 100%|██████████| 130/130 [00:08<00:00, 15.85batch/s, kl=29.3, nll=12.7]\n",
      "Epoch 38: 100%|██████████| 130/130 [00:08<00:00, 15.49batch/s, kl=29.1, nll=13.7]\n",
      "Epoch 39: 100%|██████████| 130/130 [00:08<00:00, 15.54batch/s, kl=27.4, nll=14.4]\n",
      "Epoch 40: 100%|██████████| 130/130 [00:08<00:00, 15.58batch/s, kl=28.9, nll=12]  \n",
      "Epoch 41: 100%|██████████| 130/130 [00:08<00:00, 15.68batch/s, kl=27.3, nll=12.5]\n",
      "Epoch 42: 100%|██████████| 130/130 [00:08<00:00, 15.55batch/s, kl=29, nll=14.4]  \n",
      "Epoch 43: 100%|██████████| 130/130 [00:08<00:00, 15.58batch/s, kl=25.3, nll=12.3] \n",
      "Epoch 44: 100%|██████████| 130/130 [00:08<00:00, 15.68batch/s, kl=31.8, nll=22.3]\n",
      "Epoch 45: 100%|██████████| 130/130 [00:08<00:00, 15.73batch/s, kl=26.8, nll=10.6]\n",
      "Epoch 46: 100%|██████████| 130/130 [00:08<00:00, 15.62batch/s, kl=23.7, nll=7.61]\n",
      "Epoch 47: 100%|██████████| 130/130 [00:08<00:00, 15.50batch/s, kl=22.6, nll=12.5]\n",
      "Epoch 48: 100%|██████████| 130/130 [00:08<00:00, 15.71batch/s, kl=23.8, nll=12.9]\n",
      "Epoch 49: 100%|██████████| 130/130 [00:08<00:00, 15.57batch/s, kl=22.5, nll=11.1]\n",
      "Epoch 50: 100%|██████████| 130/130 [00:08<00:00, 15.63batch/s, kl=25.4, nll=24.8]\n",
      "Epoch 51: 100%|██████████| 130/130 [00:08<00:00, 15.76batch/s, kl=25, nll=13.7]  \n",
      "Epoch 52: 100%|██████████| 130/130 [00:08<00:00, 15.83batch/s, kl=23.8, nll=11.4]\n",
      "Epoch 53: 100%|██████████| 130/130 [00:08<00:00, 15.78batch/s, kl=20.3, nll=8.09]\n",
      "Epoch 54: 100%|██████████| 130/130 [00:08<00:00, 15.64batch/s, kl=21.8, nll=12.7]\n",
      "Epoch 55: 100%|██████████| 130/130 [00:08<00:00, 15.69batch/s, kl=21.8, nll=10.9]\n",
      "Epoch 56: 100%|██████████| 130/130 [00:08<00:00, 15.70batch/s, kl=23.7, nll=18.2]\n",
      "Epoch 57: 100%|██████████| 130/130 [00:08<00:00, 15.89batch/s, kl=20.6, nll=8.21]\n",
      "Epoch 58: 100%|██████████| 130/130 [00:08<00:00, 15.50batch/s, kl=19.2, nll=11.3]\n",
      "Epoch 59: 100%|██████████| 130/130 [00:08<00:00, 15.55batch/s, kl=19, nll=6.81]  \n",
      "Epoch 60: 100%|██████████| 130/130 [00:08<00:00, 15.53batch/s, kl=17.5, nll=7.3] \n",
      "Epoch 61: 100%|██████████| 130/130 [00:08<00:00, 15.50batch/s, kl=20.2, nll=14.2]\n",
      "Epoch 62: 100%|██████████| 130/130 [00:08<00:00, 15.58batch/s, kl=19.7, nll=18.4]\n",
      "Epoch 63: 100%|██████████| 130/130 [00:08<00:00, 15.61batch/s, kl=19.1, nll=7.41]\n",
      "Epoch 64: 100%|██████████| 130/130 [00:08<00:00, 15.55batch/s, kl=21.5, nll=14]  \n",
      "Epoch 65: 100%|██████████| 130/130 [00:08<00:00, 15.60batch/s, kl=17, nll=7.82]  \n",
      "Epoch 66: 100%|██████████| 130/130 [00:08<00:00, 15.55batch/s, kl=16.5, nll=7.19]\n",
      "Epoch 67: 100%|██████████| 130/130 [00:08<00:00, 15.76batch/s, kl=16.5, nll=11.8]\n",
      "Epoch 68: 100%|██████████| 130/130 [00:08<00:00, 15.51batch/s, kl=16.7, nll=6.92]\n",
      "Epoch 69: 100%|██████████| 130/130 [00:08<00:00, 15.42batch/s, kl=16.2, nll=9.55]\n",
      "Epoch 70: 100%|██████████| 130/130 [00:08<00:00, 15.58batch/s, kl=20, nll=15.9]  \n",
      "Epoch 71: 100%|██████████| 130/130 [00:08<00:00, 15.55batch/s, kl=16.5, nll=6.87]\n",
      "Epoch 72: 100%|██████████| 130/130 [00:08<00:00, 15.63batch/s, kl=16.4, nll=13.7]\n",
      "Epoch 73: 100%|██████████| 130/130 [00:08<00:00, 15.75batch/s, kl=22.4, nll=24.8]\n",
      "Epoch 74: 100%|██████████| 130/130 [00:08<00:00, 15.68batch/s, kl=21.4, nll=8.9] \n",
      "Epoch 75: 100%|██████████| 130/130 [00:08<00:00, 15.58batch/s, kl=15.8, nll=5.51]\n",
      "Epoch 76: 100%|██████████| 130/130 [00:08<00:00, 15.53batch/s, kl=15.4, nll=11.6]\n",
      "Epoch 77: 100%|██████████| 130/130 [00:08<00:00, 15.59batch/s, kl=14.8, nll=8.49]\n",
      "Epoch 78: 100%|██████████| 130/130 [00:08<00:00, 15.47batch/s, kl=14.8, nll=8.66]\n",
      "Epoch 79: 100%|██████████| 130/130 [00:08<00:00, 15.35batch/s, kl=13.9, nll=6.32]\n",
      "Epoch 80: 100%|██████████| 130/130 [00:08<00:00, 15.56batch/s, kl=13.1, nll=7.25]\n",
      "Epoch 81: 100%|██████████| 130/130 [00:08<00:00, 15.77batch/s, kl=14.9, nll=10.5]\n",
      "Epoch 82: 100%|██████████| 130/130 [00:08<00:00, 15.62batch/s, kl=14.6, nll=10.6]\n",
      "Epoch 83: 100%|██████████| 130/130 [00:08<00:00, 15.70batch/s, kl=14.5, nll=8.86]\n",
      "Epoch 84: 100%|██████████| 130/130 [00:08<00:00, 15.66batch/s, kl=14.9, nll=10.4]\n",
      "Epoch 85: 100%|██████████| 130/130 [00:08<00:00, 15.88batch/s, kl=15.5, nll=10.4]\n",
      "Epoch 86: 100%|██████████| 130/130 [00:08<00:00, 15.67batch/s, kl=12.7, nll=6.83]\n",
      "Epoch 87: 100%|██████████| 130/130 [00:08<00:00, 15.47batch/s, kl=12.7, nll=6.62]\n",
      "Epoch 88: 100%|██████████| 130/130 [00:08<00:00, 15.57batch/s, kl=12.1, nll=8.64]\n",
      "Epoch 89: 100%|██████████| 130/130 [00:08<00:00, 15.51batch/s, kl=12.8, nll=10.7]\n",
      "Epoch 90: 100%|██████████| 130/130 [00:08<00:00, 15.69batch/s, kl=11.6, nll=4.38]\n",
      "Epoch 91: 100%|██████████| 130/130 [00:08<00:00, 15.63batch/s, kl=10.6, nll=5]   \n",
      "Epoch 92: 100%|██████████| 130/130 [00:08<00:00, 15.64batch/s, kl=10.8, nll=6.89]\n",
      "Epoch 93: 100%|██████████| 130/130 [00:08<00:00, 15.74batch/s, kl=14.6, nll=16.3]\n",
      "Epoch 94: 100%|██████████| 130/130 [00:08<00:00, 15.45batch/s, kl=14.1, nll=9.13]\n",
      "Epoch 95: 100%|██████████| 130/130 [00:08<00:00, 15.65batch/s, kl=11.2, nll=3.51]\n",
      "Epoch 96: 100%|██████████| 130/130 [00:08<00:00, 15.64batch/s, kl=11.2, nll=7.11]\n",
      "Epoch 97: 100%|██████████| 130/130 [00:08<00:00, 15.65batch/s, kl=10.8, nll=8.66]\n",
      "Epoch 98: 100%|██████████| 130/130 [00:08<00:00, 15.58batch/s, kl=10.8, nll=8.26]\n",
      "Epoch 99: 100%|██████████| 130/130 [00:08<00:00, 15.60batch/s, kl=11.1, nll=6.51]\n",
      "Epoch 100: 100%|██████████| 130/130 [00:08<00:00, 15.46batch/s, kl=11.3, nll=8.49]\n",
      "Epoch 1: 100%|██████████| 119/119 [01:46<00:00,  1.12batch/s, kl=6.78e+3, nll=332]\n",
      "Epoch 2: 100%|██████████| 119/119 [00:07<00:00, 15.80batch/s, kl=801, nll=301]   \n",
      "Epoch 3: 100%|██████████| 119/119 [00:07<00:00, 16.02batch/s, kl=241, nll=305]\n",
      "Epoch 4: 100%|██████████| 119/119 [00:07<00:00, 15.77batch/s, kl=157, nll=297]\n",
      "Epoch 5: 100%|██████████| 119/119 [00:07<00:00, 15.90batch/s, kl=134, nll=291]\n",
      "Epoch 6: 100%|██████████| 119/119 [00:07<00:00, 15.95batch/s, kl=125, nll=284]\n",
      "Epoch 7: 100%|██████████| 119/119 [00:07<00:00, 15.98batch/s, kl=121, nll=273]\n",
      "Epoch 8: 100%|██████████| 119/119 [00:07<00:00, 15.90batch/s, kl=115, nll=267]\n",
      "Epoch 9: 100%|██████████| 119/119 [00:07<00:00, 16.00batch/s, kl=112, nll=259]\n",
      "Epoch 10: 100%|██████████| 119/119 [00:07<00:00, 16.01batch/s, kl=109, nll=242]\n",
      "Epoch 11: 100%|██████████| 119/119 [00:07<00:00, 15.84batch/s, kl=102, nll=235]\n",
      "Epoch 12: 100%|██████████| 119/119 [00:07<00:00, 15.85batch/s, kl=104, nll=219]\n",
      "Epoch 13: 100%|██████████| 119/119 [00:07<00:00, 15.85batch/s, kl=122, nll=156]\n",
      "Epoch 14: 100%|██████████| 119/119 [00:07<00:00, 15.80batch/s, kl=125, nll=47.1]\n",
      "Epoch 15: 100%|██████████| 119/119 [00:07<00:00, 15.84batch/s, kl=106, nll=58.2]\n",
      "Epoch 16: 100%|██████████| 119/119 [00:07<00:00, 15.92batch/s, kl=92.3, nll=29.5]\n",
      "Epoch 17: 100%|██████████| 119/119 [00:07<00:00, 15.90batch/s, kl=76.3, nll=25.3]\n",
      "Epoch 18: 100%|██████████| 119/119 [00:07<00:00, 15.82batch/s, kl=82.5, nll=31.8]\n",
      "Epoch 19: 100%|██████████| 119/119 [00:07<00:00, 15.91batch/s, kl=71.4, nll=37.3]\n",
      "Epoch 20: 100%|██████████| 119/119 [00:07<00:00, 15.75batch/s, kl=68.3, nll=26]  \n",
      "Epoch 21: 100%|██████████| 119/119 [00:07<00:00, 15.91batch/s, kl=63.1, nll=19.6]\n",
      "Epoch 22: 100%|██████████| 119/119 [00:07<00:00, 15.93batch/s, kl=59, nll=24.3]  \n",
      "Epoch 23: 100%|██████████| 119/119 [00:07<00:00, 15.85batch/s, kl=55.6, nll=18.9]\n",
      "Epoch 24: 100%|██████████| 119/119 [00:07<00:00, 15.87batch/s, kl=58.6, nll=19.5]\n",
      "Epoch 25: 100%|██████████| 119/119 [00:07<00:00, 15.94batch/s, kl=53.4, nll=34]  \n",
      "Epoch 26: 100%|██████████| 119/119 [00:07<00:00, 15.95batch/s, kl=54.1, nll=19.9]\n",
      "Epoch 27: 100%|██████████| 119/119 [00:07<00:00, 15.91batch/s, kl=47.1, nll=12.8]\n",
      "Epoch 28: 100%|██████████| 119/119 [00:07<00:00, 15.84batch/s, kl=48.8, nll=26.3]\n",
      "Epoch 29: 100%|██████████| 119/119 [00:07<00:00, 15.97batch/s, kl=44.2, nll=18]  \n",
      "Epoch 30: 100%|██████████| 119/119 [00:07<00:00, 15.89batch/s, kl=44.8, nll=14.7]\n",
      "Epoch 31: 100%|██████████| 119/119 [00:07<00:00, 16.15batch/s, kl=41.3, nll=20.1]\n",
      "Epoch 32: 100%|██████████| 119/119 [00:07<00:00, 15.79batch/s, kl=40.7, nll=16.7]\n",
      "Epoch 33: 100%|██████████| 119/119 [00:07<00:00, 15.65batch/s, kl=38.1, nll=11.6]\n",
      "Epoch 34: 100%|██████████| 119/119 [00:07<00:00, 15.78batch/s, kl=39.2, nll=19.9]\n",
      "Epoch 35: 100%|██████████| 119/119 [00:07<00:00, 15.72batch/s, kl=36, nll=10.6]  \n",
      "Epoch 36: 100%|██████████| 119/119 [00:07<00:00, 15.92batch/s, kl=37, nll=15.5]  \n",
      "Epoch 37: 100%|██████████| 119/119 [00:07<00:00, 15.78batch/s, kl=35.6, nll=17.5]\n",
      "Epoch 38: 100%|██████████| 119/119 [00:07<00:00, 15.72batch/s, kl=34.4, nll=18.2]\n",
      "Epoch 39: 100%|██████████| 119/119 [00:07<00:00, 15.98batch/s, kl=35.1, nll=11.6]\n",
      "Epoch 40: 100%|██████████| 119/119 [00:07<00:00, 16.04batch/s, kl=33.8, nll=18.6]\n",
      "Epoch 41: 100%|██████████| 119/119 [00:07<00:00, 15.88batch/s, kl=31.4, nll=15.4]\n",
      "Epoch 42: 100%|██████████| 119/119 [00:07<00:00, 15.80batch/s, kl=31.7, nll=13.9]\n",
      "Epoch 43: 100%|██████████| 119/119 [00:07<00:00, 15.90batch/s, kl=29.9, nll=13]  \n",
      "Epoch 44: 100%|██████████| 119/119 [00:07<00:00, 15.99batch/s, kl=29.5, nll=12.9]\n",
      "Epoch 45: 100%|██████████| 119/119 [00:07<00:00, 15.76batch/s, kl=26.7, nll=10.2]\n",
      "Epoch 46: 100%|██████████| 119/119 [00:07<00:00, 15.66batch/s, kl=27.2, nll=12.4]\n",
      "Epoch 47: 100%|██████████| 119/119 [00:07<00:00, 15.90batch/s, kl=27.2, nll=16.2]\n",
      "Epoch 48: 100%|██████████| 119/119 [00:07<00:00, 15.82batch/s, kl=27.8, nll=8.98]\n",
      "Epoch 49: 100%|██████████| 119/119 [00:07<00:00, 15.89batch/s, kl=25.9, nll=12.5]\n",
      "Epoch 50: 100%|██████████| 119/119 [00:07<00:00, 15.81batch/s, kl=27.1, nll=17]  \n",
      "Epoch 51: 100%|██████████| 119/119 [00:07<00:00, 15.83batch/s, kl=25.2, nll=13.4]\n",
      "Epoch 52: 100%|██████████| 119/119 [00:07<00:00, 15.98batch/s, kl=26.9, nll=17.7]\n",
      "Epoch 53: 100%|██████████| 119/119 [00:07<00:00, 15.91batch/s, kl=23.6, nll=7.88]\n",
      "Epoch 54: 100%|██████████| 119/119 [00:07<00:00, 15.96batch/s, kl=25.3, nll=21]  \n",
      "Epoch 55: 100%|██████████| 119/119 [00:07<00:00, 15.91batch/s, kl=26.2, nll=13.4]\n",
      "Epoch 56: 100%|██████████| 119/119 [00:07<00:00, 15.84batch/s, kl=22.1, nll=5.98]\n",
      "Epoch 57: 100%|██████████| 119/119 [00:07<00:00, 15.87batch/s, kl=27.2, nll=23.6]\n",
      "Epoch 58: 100%|██████████| 119/119 [00:07<00:00, 15.85batch/s, kl=23, nll=6.42]  \n",
      "Epoch 59: 100%|██████████| 119/119 [00:07<00:00, 16.01batch/s, kl=21.7, nll=17.6]\n",
      "Epoch 60: 100%|██████████| 119/119 [00:07<00:00, 15.87batch/s, kl=23.1, nll=11.5]\n",
      "Epoch 61: 100%|██████████| 119/119 [00:07<00:00, 15.69batch/s, kl=21.1, nll=14.1]\n",
      "Epoch 62: 100%|██████████| 119/119 [00:07<00:00, 15.80batch/s, kl=23.1, nll=12.4]\n",
      "Epoch 63: 100%|██████████| 119/119 [00:07<00:00, 15.89batch/s, kl=20.1, nll=8.04]\n",
      "Epoch 64: 100%|██████████| 119/119 [00:07<00:00, 15.77batch/s, kl=19.6, nll=11.8]\n",
      "Epoch 65: 100%|██████████| 119/119 [00:07<00:00, 15.89batch/s, kl=21.2, nll=13.2]\n",
      "Epoch 66: 100%|██████████| 119/119 [00:07<00:00, 15.91batch/s, kl=20.7, nll=13.2]\n",
      "Epoch 67: 100%|██████████| 119/119 [00:07<00:00, 15.94batch/s, kl=18.7, nll=10.2]\n",
      "Epoch 68: 100%|██████████| 119/119 [00:07<00:00, 15.82batch/s, kl=18.5, nll=7.67]\n",
      "Epoch 69: 100%|██████████| 119/119 [00:07<00:00, 15.94batch/s, kl=18.8, nll=10.4]\n",
      "Epoch 70: 100%|██████████| 119/119 [00:07<00:00, 15.73batch/s, kl=17.2, nll=5.95]\n",
      "Epoch 71: 100%|██████████| 119/119 [00:07<00:00, 16.03batch/s, kl=20.8, nll=10.4]\n",
      "Epoch 72: 100%|██████████| 119/119 [00:07<00:00, 15.84batch/s, kl=17.3, nll=3.56]\n",
      "Epoch 73: 100%|██████████| 119/119 [00:07<00:00, 15.93batch/s, kl=16.3, nll=8.07]\n",
      "Epoch 74: 100%|██████████| 119/119 [00:07<00:00, 16.06batch/s, kl=17.4, nll=13.3]\n",
      "Epoch 75: 100%|██████████| 119/119 [00:07<00:00, 15.87batch/s, kl=18.6, nll=17.2]\n",
      "Epoch 76: 100%|██████████| 119/119 [00:07<00:00, 15.78batch/s, kl=17, nll=8.44]  \n",
      "Epoch 77: 100%|██████████| 119/119 [00:07<00:00, 15.90batch/s, kl=15.7, nll=10.6]\n",
      "Epoch 78: 100%|██████████| 119/119 [00:07<00:00, 16.06batch/s, kl=19, nll=11]    \n",
      "Epoch 79: 100%|██████████| 119/119 [00:07<00:00, 15.92batch/s, kl=16, nll=8.42] \n",
      "Epoch 80: 100%|██████████| 119/119 [00:07<00:00, 15.94batch/s, kl=15, nll=8.45]  \n",
      "Epoch 81: 100%|██████████| 119/119 [00:07<00:00, 15.91batch/s, kl=14.5, nll=8.12]\n",
      "Epoch 82: 100%|██████████| 119/119 [00:07<00:00, 15.95batch/s, kl=15.8, nll=14.9]\n",
      "Epoch 83: 100%|██████████| 119/119 [00:07<00:00, 15.90batch/s, kl=14.7, nll=6.04]\n",
      "Epoch 84: 100%|██████████| 119/119 [00:07<00:00, 15.97batch/s, kl=13.9, nll=5.56]\n",
      "Epoch 85: 100%|██████████| 119/119 [00:07<00:00, 15.88batch/s, kl=13.3, nll=8.16]\n",
      "Epoch 86: 100%|██████████| 119/119 [00:07<00:00, 16.07batch/s, kl=16.6, nll=12.5]\n",
      "Epoch 87: 100%|██████████| 119/119 [00:07<00:00, 15.90batch/s, kl=14.8, nll=10.2]\n",
      "Epoch 88: 100%|██████████| 119/119 [00:07<00:00, 15.86batch/s, kl=13, nll=3.83]  \n",
      "Epoch 89: 100%|██████████| 119/119 [00:07<00:00, 15.81batch/s, kl=13.9, nll=12.7]\n",
      "Epoch 90: 100%|██████████| 119/119 [00:07<00:00, 15.81batch/s, kl=15.4, nll=7.13]\n",
      "Epoch 91: 100%|██████████| 119/119 [00:07<00:00, 15.90batch/s, kl=13, nll=8.21]  \n",
      "Epoch 92: 100%|██████████| 119/119 [00:07<00:00, 15.93batch/s, kl=13.1, nll=6.83]\n",
      "Epoch 93: 100%|██████████| 119/119 [00:07<00:00, 16.03batch/s, kl=12.2, nll=6.34]\n",
      "Epoch 94: 100%|██████████| 119/119 [00:07<00:00, 15.79batch/s, kl=13.8, nll=13.2]\n",
      "Epoch 95: 100%|██████████| 119/119 [00:07<00:00, 15.94batch/s, kl=18.8, nll=8.14]\n",
      "Epoch 96: 100%|██████████| 119/119 [00:07<00:00, 15.94batch/s, kl=15.1, nll=13.4]\n",
      "Epoch 97: 100%|██████████| 119/119 [00:07<00:00, 15.76batch/s, kl=12.8, nll=4.48]\n",
      "Epoch 98: 100%|██████████| 119/119 [00:07<00:00, 15.85batch/s, kl=11.7, nll=5.03]\n",
      "Epoch 99: 100%|██████████| 119/119 [00:07<00:00, 15.99batch/s, kl=11.4, nll=6.9] \n",
      "Epoch 100: 100%|██████████| 119/119 [00:07<00:00, 15.81batch/s, kl=10.8, nll=5.24]\n",
      "Epoch 1: 100%|██████████| 107/107 [01:48<00:00,  1.01s/batch, kl=7.22e+3, nll=342]\n",
      "Epoch 2: 100%|██████████| 107/107 [00:06<00:00, 15.83batch/s, kl=1.01e+3, nll=308]\n",
      "Epoch 3: 100%|██████████| 107/107 [00:06<00:00, 15.90batch/s, kl=303, nll=314]\n",
      "Epoch 4: 100%|██████████| 107/107 [00:06<00:00, 15.91batch/s, kl=172, nll=308]\n",
      "Epoch 5: 100%|██████████| 107/107 [00:06<00:00, 16.02batch/s, kl=142, nll=302]\n",
      "Epoch 6: 100%|██████████| 107/107 [00:06<00:00, 15.83batch/s, kl=130, nll=293]\n",
      "Epoch 7: 100%|██████████| 107/107 [00:06<00:00, 16.12batch/s, kl=122, nll=286]\n",
      "Epoch 8: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=119, nll=278]\n",
      "Epoch 9: 100%|██████████| 107/107 [00:06<00:00, 16.03batch/s, kl=116, nll=270]\n",
      "Epoch 10: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=114, nll=258]\n",
      "Epoch 11: 100%|██████████| 107/107 [00:06<00:00, 16.13batch/s, kl=108, nll=252]\n",
      "Epoch 12: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=112, nll=226]\n",
      "Epoch 13: 100%|██████████| 107/107 [00:06<00:00, 15.70batch/s, kl=126, nll=165]\n",
      "Epoch 14: 100%|██████████| 107/107 [00:06<00:00, 15.83batch/s, kl=129, nll=48.3]\n",
      "Epoch 15: 100%|██████████| 107/107 [00:06<00:00, 16.03batch/s, kl=94.2, nll=34.6]\n",
      "Epoch 16: 100%|██████████| 107/107 [00:06<00:00, 15.94batch/s, kl=88.4, nll=64.3]\n",
      "Epoch 17: 100%|██████████| 107/107 [00:06<00:00, 15.89batch/s, kl=102, nll=48]  \n",
      "Epoch 18: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=79.9, nll=27.7]\n",
      "Epoch 19: 100%|██████████| 107/107 [00:06<00:00, 15.90batch/s, kl=70.1, nll=35.1]\n",
      "Epoch 20: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=66.3, nll=21.3]\n",
      "Epoch 21: 100%|██████████| 107/107 [00:06<00:00, 15.96batch/s, kl=61.1, nll=23.3]\n",
      "Epoch 22: 100%|██████████| 107/107 [00:06<00:00, 16.00batch/s, kl=58.9, nll=25.9]\n",
      "Epoch 23: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=56.1, nll=19.6]\n",
      "Epoch 24: 100%|██████████| 107/107 [00:06<00:00, 15.98batch/s, kl=51.4, nll=15]  \n",
      "Epoch 25: 100%|██████████| 107/107 [00:06<00:00, 16.10batch/s, kl=52, nll=29.8]  \n",
      "Epoch 26: 100%|██████████| 107/107 [00:06<00:00, 16.09batch/s, kl=50.9, nll=22]  \n",
      "Epoch 27: 100%|██████████| 107/107 [00:06<00:00, 16.06batch/s, kl=49.2, nll=26.6]\n",
      "Epoch 28: 100%|██████████| 107/107 [00:06<00:00, 15.75batch/s, kl=52.5, nll=30.1]\n",
      "Epoch 29: 100%|██████████| 107/107 [00:06<00:00, 15.83batch/s, kl=48.8, nll=14.9]\n",
      "Epoch 30: 100%|██████████| 107/107 [00:06<00:00, 15.74batch/s, kl=46.5, nll=25.7]\n",
      "Epoch 31: 100%|██████████| 107/107 [00:06<00:00, 15.89batch/s, kl=43.3, nll=9.95]\n",
      "Epoch 32: 100%|██████████| 107/107 [00:06<00:00, 15.76batch/s, kl=39.7, nll=19.1]\n",
      "Epoch 33: 100%|██████████| 107/107 [00:06<00:00, 16.06batch/s, kl=42.8, nll=19.7]\n",
      "Epoch 34: 100%|██████████| 107/107 [00:06<00:00, 15.94batch/s, kl=38.8, nll=13.7]\n",
      "Epoch 35: 100%|██████████| 107/107 [00:06<00:00, 16.01batch/s, kl=36.9, nll=16.2]\n",
      "Epoch 36: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=36.1, nll=14.9]\n",
      "Epoch 37: 100%|██████████| 107/107 [00:06<00:00, 15.96batch/s, kl=37.6, nll=13]  \n",
      "Epoch 38: 100%|██████████| 107/107 [00:06<00:00, 15.91batch/s, kl=37.4, nll=20.8]\n",
      "Epoch 39: 100%|██████████| 107/107 [00:06<00:00, 15.88batch/s, kl=35.5, nll=8.31]\n",
      "Epoch 40: 100%|██████████| 107/107 [00:06<00:00, 16.05batch/s, kl=34.7, nll=26.6]\n",
      "Epoch 41: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=34.9, nll=22.4]\n",
      "Epoch 42: 100%|██████████| 107/107 [00:06<00:00, 15.99batch/s, kl=35.8, nll=16.5]\n",
      "Epoch 43: 100%|██████████| 107/107 [00:06<00:00, 15.91batch/s, kl=36, nll=16.1]  \n",
      "Epoch 44: 100%|██████████| 107/107 [00:06<00:00, 15.88batch/s, kl=31, nll=23.6]  \n",
      "Epoch 45: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=34.5, nll=15.7]\n",
      "Epoch 46: 100%|██████████| 107/107 [00:06<00:00, 15.86batch/s, kl=30.2, nll=17.5]\n",
      "Epoch 47: 100%|██████████| 107/107 [00:06<00:00, 15.72batch/s, kl=27.8, nll=10.3]\n",
      "Epoch 48: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=27.5, nll=18]  \n",
      "Epoch 49: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=30.5, nll=11]  \n",
      "Epoch 50: 100%|██████████| 107/107 [00:06<00:00, 15.93batch/s, kl=27.8, nll=14.6]\n",
      "Epoch 51: 100%|██████████| 107/107 [00:06<00:00, 15.82batch/s, kl=25.7, nll=13.3]\n",
      "Epoch 52: 100%|██████████| 107/107 [00:06<00:00, 15.86batch/s, kl=25, nll=9.69] \n",
      "Epoch 53: 100%|██████████| 107/107 [00:06<00:00, 15.96batch/s, kl=26, nll=18.9]  \n",
      "Epoch 54: 100%|██████████| 107/107 [00:06<00:00, 15.86batch/s, kl=24.4, nll=7.95]\n",
      "Epoch 55: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=29, nll=26.7]  \n",
      "Epoch 56: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=27.3, nll=7.02]\n",
      "Epoch 57: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=22.5, nll=6.93]\n",
      "Epoch 58: 100%|██████████| 107/107 [00:06<00:00, 15.82batch/s, kl=22, nll=12.3]  \n",
      "Epoch 59: 100%|██████████| 107/107 [00:06<00:00, 15.95batch/s, kl=24.8, nll=21.1]\n",
      "Epoch 60: 100%|██████████| 107/107 [00:06<00:00, 15.96batch/s, kl=23.6, nll=9.56]\n",
      "Epoch 61: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=21.4, nll=8.46]\n",
      "Epoch 62: 100%|██████████| 107/107 [00:06<00:00, 15.91batch/s, kl=22.5, nll=19.5]\n",
      "Epoch 63: 100%|██████████| 107/107 [00:06<00:00, 16.04batch/s, kl=21.6, nll=9.68]\n",
      "Epoch 64: 100%|██████████| 107/107 [00:06<00:00, 15.93batch/s, kl=20.5, nll=15.7]\n",
      "Epoch 65: 100%|██████████| 107/107 [00:06<00:00, 15.97batch/s, kl=24.6, nll=20.7]\n",
      "Epoch 66: 100%|██████████| 107/107 [00:06<00:00, 15.95batch/s, kl=30.2, nll=16.4]\n",
      "Epoch 67: 100%|██████████| 107/107 [00:06<00:00, 15.97batch/s, kl=23.3, nll=12.1]\n",
      "Epoch 68: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=20.4, nll=10.6]\n",
      "Epoch 69: 100%|██████████| 107/107 [00:06<00:00, 16.06batch/s, kl=19.6, nll=6.49]\n",
      "Epoch 70: 100%|██████████| 107/107 [00:06<00:00, 16.02batch/s, kl=20.5, nll=6.15]\n",
      "Epoch 71: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=16.9, nll=4.74]\n",
      "Epoch 72: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=21.7, nll=20.3]\n",
      "Epoch 73: 100%|██████████| 107/107 [00:06<00:00, 15.98batch/s, kl=19, nll=7.92]  \n",
      "Epoch 74: 100%|██████████| 107/107 [00:06<00:00, 15.77batch/s, kl=31.3, nll=20.7]\n",
      "Epoch 75: 100%|██████████| 107/107 [00:06<00:00, 15.99batch/s, kl=21.7, nll=6.37]\n",
      "Epoch 76: 100%|██████████| 107/107 [00:06<00:00, 15.98batch/s, kl=16.9, nll=10.9]\n",
      "Epoch 77: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=18.6, nll=14.8]\n",
      "Epoch 78: 100%|██████████| 107/107 [00:06<00:00, 15.99batch/s, kl=16.4, nll=8.49]\n",
      "Epoch 79: 100%|██████████| 107/107 [00:06<00:00, 15.83batch/s, kl=19.1, nll=14.8]\n",
      "Epoch 80: 100%|██████████| 107/107 [00:06<00:00, 15.94batch/s, kl=17.2, nll=12.3]\n",
      "Epoch 81: 100%|██████████| 107/107 [00:06<00:00, 16.12batch/s, kl=16.4, nll=7.77]\n",
      "Epoch 82: 100%|██████████| 107/107 [00:06<00:00, 15.85batch/s, kl=15.3, nll=8.91]\n",
      "Epoch 83: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=15.3, nll=12.7]\n",
      "Epoch 84: 100%|██████████| 107/107 [00:06<00:00, 15.76batch/s, kl=18.6, nll=21.5]\n",
      "Epoch 85: 100%|██████████| 107/107 [00:06<00:00, 15.94batch/s, kl=17.1, nll=7.67]\n",
      "Epoch 86: 100%|██████████| 107/107 [00:06<00:00, 15.90batch/s, kl=16.7, nll=7.69]\n",
      "Epoch 87: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=14.5, nll=11.3]\n",
      "Epoch 88: 100%|██████████| 107/107 [00:06<00:00, 15.79batch/s, kl=18.3, nll=17.9]\n",
      "Epoch 89: 100%|██████████| 107/107 [00:06<00:00, 15.68batch/s, kl=19.1, nll=8.51]\n",
      "Epoch 90: 100%|██████████| 107/107 [00:06<00:00, 15.81batch/s, kl=19.3, nll=12.4]\n",
      "Epoch 91: 100%|██████████| 107/107 [00:06<00:00, 15.92batch/s, kl=15.5, nll=11.5]\n",
      "Epoch 92: 100%|██████████| 107/107 [00:06<00:00, 15.94batch/s, kl=15.3, nll=5.71]\n",
      "Epoch 93: 100%|██████████| 107/107 [00:06<00:00, 15.90batch/s, kl=14, nll=3.84] \n",
      "Epoch 94: 100%|██████████| 107/107 [00:06<00:00, 15.74batch/s, kl=16.8, nll=16]  \n",
      "Epoch 95: 100%|██████████| 107/107 [00:06<00:00, 16.04batch/s, kl=15.8, nll=12.8]\n",
      "Epoch 96: 100%|██████████| 107/107 [00:06<00:00, 15.81batch/s, kl=14.8, nll=8.66]\n",
      "Epoch 97: 100%|██████████| 107/107 [00:06<00:00, 15.95batch/s, kl=14.5, nll=5.07]\n",
      "Epoch 98: 100%|██████████| 107/107 [00:06<00:00, 16.01batch/s, kl=15.7, nll=15.1]\n",
      "Epoch 99: 100%|██████████| 107/107 [00:06<00:00, 15.99batch/s, kl=15, nll=7.72]  \n",
      "Epoch 100: 100%|██████████| 107/107 [00:06<00:00, 15.87batch/s, kl=14.5, nll=5.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m-18.23   \u001b[0m | \u001b[0m100.9    \u001b[0m | \u001b[0m-0.839   \u001b[0m | \u001b[0m-4.0     \u001b[0m | \u001b[0m44.19    \u001b[0m | \u001b[0m-2.56    \u001b[0m | \u001b[0m-2.723   \u001b[0m | \u001b[0m-2.441   \u001b[0m | \u001b[0m59.56    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 142/142 [01:47<00:00,  1.32batch/s, kl=55.9, nll=70.4]\n",
      "Epoch 2: 100%|██████████| 142/142 [00:08<00:00, 16.73batch/s, kl=54.5, nll=1.07]\n",
      "Epoch 3: 100%|██████████| 142/142 [00:08<00:00, 16.78batch/s, kl=53.1, nll=-.244]  \n",
      "Epoch 4: 100%|██████████| 142/142 [00:08<00:00, 16.71batch/s, kl=51.6, nll=-.704] \n",
      "Epoch 5: 100%|██████████| 142/142 [00:08<00:00, 16.34batch/s, kl=50.1, nll=-.943]\n",
      "Epoch 6: 100%|██████████| 142/142 [00:08<00:00, 16.53batch/s, kl=48.5, nll=-1.07]\n",
      "Epoch 7: 100%|██████████| 142/142 [00:08<00:00, 16.53batch/s, kl=47, nll=-1.16]  \n",
      "Epoch 8: 100%|██████████| 142/142 [00:08<00:00, 16.57batch/s, kl=45.4, nll=-1.24]\n",
      "Epoch 9: 100%|██████████| 142/142 [00:08<00:00, 16.51batch/s, kl=43.8, nll=-1.28]\n",
      "Epoch 10: 100%|██████████| 142/142 [00:08<00:00, 16.72batch/s, kl=42.3, nll=-1.32]\n",
      "Epoch 11: 100%|██████████| 142/142 [00:08<00:00, 16.65batch/s, kl=40.7, nll=-1.33]\n",
      "Epoch 12: 100%|██████████| 142/142 [00:08<00:00, 16.49batch/s, kl=39.1, nll=-1.36]\n",
      "Epoch 13: 100%|██████████| 142/142 [00:08<00:00, 16.57batch/s, kl=37.5, nll=-1.37]\n",
      "Epoch 14: 100%|██████████| 142/142 [00:08<00:00, 16.60batch/s, kl=36, nll=-1.37]  \n",
      "Epoch 15: 100%|██████████| 142/142 [00:08<00:00, 16.71batch/s, kl=34.4, nll=-1.37]\n",
      "Epoch 16: 100%|██████████| 142/142 [00:08<00:00, 16.89batch/s, kl=32.9, nll=-1.38]\n",
      "Epoch 17: 100%|██████████| 142/142 [00:08<00:00, 16.78batch/s, kl=31.4, nll=-1.37]\n",
      "Epoch 18: 100%|██████████| 142/142 [00:08<00:00, 16.79batch/s, kl=29.8, nll=-1.36]\n",
      "Epoch 19: 100%|██████████| 142/142 [00:08<00:00, 16.60batch/s, kl=28.3, nll=-1.35]\n",
      "Epoch 20: 100%|██████████| 142/142 [00:08<00:00, 16.51batch/s, kl=26.7, nll=-1.35]\n",
      "Epoch 21: 100%|██████████| 142/142 [00:08<00:00, 16.42batch/s, kl=25.2, nll=-1.34]\n",
      "Epoch 22: 100%|██████████| 142/142 [00:08<00:00, 16.54batch/s, kl=23.6, nll=-1.33]\n",
      "Epoch 23: 100%|██████████| 142/142 [00:08<00:00, 16.75batch/s, kl=22, nll=-1.32]  \n",
      "Epoch 24: 100%|██████████| 142/142 [00:08<00:00, 16.59batch/s, kl=20.5, nll=-1.3] \n",
      "Epoch 25: 100%|██████████| 142/142 [00:08<00:00, 16.71batch/s, kl=18.9, nll=-1.3] \n",
      "Epoch 26: 100%|██████████| 142/142 [00:08<00:00, 16.67batch/s, kl=17.4, nll=-1.3] \n",
      "Epoch 27: 100%|██████████| 142/142 [00:08<00:00, 16.76batch/s, kl=15.9, nll=-1.32]\n",
      "Epoch 28: 100%|██████████| 142/142 [00:08<00:00, 16.71batch/s, kl=14.5, nll=-1.32]\n",
      "Epoch 29: 100%|██████████| 142/142 [00:08<00:00, 16.63batch/s, kl=13.2, nll=-1.33]\n",
      "Epoch 30: 100%|██████████| 142/142 [00:08<00:00, 16.73batch/s, kl=11.9, nll=-1.34]\n",
      "Epoch 31: 100%|██████████| 142/142 [00:08<00:00, 16.65batch/s, kl=10.7, nll=-1.35]\n",
      "Epoch 32: 100%|██████████| 142/142 [00:08<00:00, 16.65batch/s, kl=9.7, nll=-1.37] \n",
      "Epoch 33: 100%|██████████| 142/142 [00:08<00:00, 16.63batch/s, kl=8.78, nll=-1.37]\n",
      "Epoch 34: 100%|██████████| 142/142 [00:08<00:00, 16.57batch/s, kl=7.99, nll=-1.38]\n",
      "Epoch 35: 100%|██████████| 142/142 [00:08<00:00, 16.62batch/s, kl=7.31, nll=-1.39]\n",
      "Epoch 36: 100%|██████████| 142/142 [00:08<00:00, 16.57batch/s, kl=6.74, nll=-1.38]\n",
      "Epoch 37: 100%|██████████| 142/142 [00:08<00:00, 16.46batch/s, kl=6.27, nll=-1.36]\n",
      "Epoch 38: 100%|██████████| 142/142 [00:08<00:00, 16.64batch/s, kl=5.87, nll=-1.27]\n",
      "Epoch 39: 100%|██████████| 142/142 [00:08<00:00, 16.43batch/s, kl=5.56, nll=-1.33]\n",
      "Epoch 40: 100%|██████████| 142/142 [00:08<00:00, 16.59batch/s, kl=5.26, nll=-1.42]\n",
      "Epoch 41: 100%|██████████| 142/142 [00:08<00:00, 16.64batch/s, kl=5.01, nll=-1.42]\n",
      "Epoch 42: 100%|██████████| 142/142 [00:08<00:00, 16.69batch/s, kl=4.81, nll=-1.42]\n",
      "Epoch 43: 100%|██████████| 142/142 [00:08<00:00, 16.43batch/s, kl=4.61, nll=-1.42]\n",
      "Epoch 44: 100%|██████████| 142/142 [00:08<00:00, 16.52batch/s, kl=4.44, nll=-1.42]\n",
      "Epoch 45: 100%|██████████| 142/142 [00:08<00:00, 16.53batch/s, kl=4.28, nll=-1.42]\n",
      "Epoch 46: 100%|██████████| 142/142 [00:08<00:00, 16.54batch/s, kl=4.13, nll=-1.43]\n",
      "Epoch 47: 100%|██████████| 142/142 [00:08<00:00, 16.68batch/s, kl=3.99, nll=-1.42]\n",
      "Epoch 48: 100%|██████████| 142/142 [00:08<00:00, 16.67batch/s, kl=3.85, nll=-1.43]\n",
      "Epoch 49: 100%|██████████| 142/142 [00:08<00:00, 16.87batch/s, kl=3.72, nll=-1.42]\n",
      "Epoch 50: 100%|██████████| 142/142 [00:08<00:00, 16.73batch/s, kl=3.6, nll=-1.43] \n",
      "Epoch 51: 100%|██████████| 142/142 [00:08<00:00, 16.40batch/s, kl=3.48, nll=-1.42]\n",
      "Epoch 52: 100%|██████████| 142/142 [00:08<00:00, 16.65batch/s, kl=3.37, nll=-1.42]\n",
      "Epoch 53: 100%|██████████| 142/142 [00:08<00:00, 16.45batch/s, kl=3.27, nll=-1.43]\n",
      "Epoch 54: 100%|██████████| 142/142 [00:08<00:00, 16.46batch/s, kl=3.17, nll=-1.44]\n",
      "Epoch 55: 100%|██████████| 142/142 [00:08<00:00, 16.52batch/s, kl=3.07, nll=-1.44]\n",
      "Epoch 56: 100%|██████████| 142/142 [00:08<00:00, 16.58batch/s, kl=2.98, nll=-1.44]\n",
      "Epoch 57: 100%|██████████| 142/142 [00:08<00:00, 16.65batch/s, kl=2.9, nll=-1.44] \n",
      "Epoch 58: 100%|██████████| 142/142 [00:08<00:00, 16.78batch/s, kl=2.81, nll=-1.45]\n",
      "Epoch 59: 100%|██████████| 142/142 [00:08<00:00, 16.61batch/s, kl=2.74, nll=-1.44]\n",
      "Epoch 60: 100%|██████████| 142/142 [00:08<00:00, 16.58batch/s, kl=2.66, nll=-1.45]\n",
      "Epoch 61: 100%|██████████| 142/142 [00:08<00:00, 16.63batch/s, kl=2.59, nll=-1.45]\n",
      "Epoch 62: 100%|██████████| 142/142 [00:08<00:00, 16.65batch/s, kl=2.51, nll=-1.45]\n",
      "Epoch 63: 100%|██████████| 142/142 [00:08<00:00, 16.66batch/s, kl=2.44, nll=-1.45]\n",
      "Epoch 64: 100%|██████████| 142/142 [00:08<00:00, 16.87batch/s, kl=2.38, nll=-1.46]\n",
      "Epoch 65: 100%|██████████| 142/142 [00:08<00:00, 16.60batch/s, kl=2.32, nll=-1.46]\n",
      "Epoch 66: 100%|██████████| 142/142 [00:08<00:00, 16.73batch/s, kl=2.26, nll=-1.46]\n",
      "Epoch 67: 100%|██████████| 142/142 [00:08<00:00, 16.77batch/s, kl=2.2, nll=-1.46] \n",
      "Epoch 68: 100%|██████████| 142/142 [00:08<00:00, 16.69batch/s, kl=2.14, nll=-1.46]\n",
      "Epoch 69: 100%|██████████| 142/142 [00:08<00:00, 16.44batch/s, kl=2.09, nll=-1.47]\n",
      "Epoch 70: 100%|██████████| 142/142 [00:08<00:00, 16.52batch/s, kl=2.04, nll=-1.47]\n",
      "Epoch 71: 100%|██████████| 142/142 [00:08<00:00, 16.60batch/s, kl=1.99, nll=-1.47]\n",
      "Epoch 72: 100%|██████████| 142/142 [00:08<00:00, 16.89batch/s, kl=1.95, nll=-1.47]\n",
      "Epoch 73: 100%|██████████| 142/142 [00:08<00:00, 16.72batch/s, kl=1.91, nll=-1.47]\n",
      "Epoch 74: 100%|██████████| 142/142 [00:08<00:00, 16.63batch/s, kl=1.87, nll=-1.47]\n",
      "Epoch 75: 100%|██████████| 142/142 [00:08<00:00, 16.47batch/s, kl=1.83, nll=-1.48]\n",
      "Epoch 76: 100%|██████████| 142/142 [00:08<00:00, 16.72batch/s, kl=1.79, nll=-1.48]\n",
      "Epoch 77: 100%|██████████| 142/142 [00:08<00:00, 16.76batch/s, kl=1.76, nll=-1.48]\n",
      "Epoch 78: 100%|██████████| 142/142 [00:08<00:00, 16.76batch/s, kl=1.73, nll=-1.48]\n",
      "Epoch 79: 100%|██████████| 142/142 [00:08<00:00, 16.65batch/s, kl=1.7, nll=-1.48]\n",
      "Epoch 80: 100%|██████████| 142/142 [00:08<00:00, 16.81batch/s, kl=1.67, nll=-1.49]\n",
      "Epoch 81: 100%|██████████| 142/142 [00:08<00:00, 16.73batch/s, kl=1.64, nll=-1.49]\n",
      "Epoch 82: 100%|██████████| 142/142 [00:08<00:00, 16.41batch/s, kl=1.61, nll=-1.47]\n",
      "Epoch 83: 100%|██████████| 142/142 [00:08<00:00, 16.64batch/s, kl=1.58, nll=-1.49]\n",
      "Epoch 84: 100%|██████████| 142/142 [00:08<00:00, 16.59batch/s, kl=1.56, nll=-1.49]\n",
      "Epoch 85: 100%|██████████| 142/142 [00:08<00:00, 16.57batch/s, kl=1.53, nll=-1.49]\n",
      "Epoch 86: 100%|██████████| 142/142 [00:08<00:00, 16.69batch/s, kl=1.51, nll=-1.5] \n",
      "Epoch 87: 100%|██████████| 142/142 [00:08<00:00, 16.68batch/s, kl=1.49, nll=-1.49]\n",
      "Epoch 88: 100%|██████████| 142/142 [00:08<00:00, 16.69batch/s, kl=1.46, nll=-1.49]\n",
      "Epoch 89: 100%|██████████| 142/142 [00:08<00:00, 16.60batch/s, kl=1.44, nll=-1.5] \n",
      "Epoch 90: 100%|██████████| 142/142 [00:08<00:00, 16.64batch/s, kl=1.43, nll=-1.5] \n",
      "Epoch 91: 100%|██████████| 142/142 [00:08<00:00, 16.64batch/s, kl=1.4, nll=-1.5]  \n",
      "Epoch 92: 100%|██████████| 142/142 [00:08<00:00, 16.50batch/s, kl=1.39, nll=-1.5] \n",
      "Epoch 93: 100%|██████████| 142/142 [00:08<00:00, 16.70batch/s, kl=1.37, nll=-1.5] \n",
      "Epoch 94: 100%|██████████| 142/142 [00:08<00:00, 16.73batch/s, kl=1.35, nll=-1.51]\n",
      "Epoch 95: 100%|██████████| 142/142 [00:08<00:00, 16.35batch/s, kl=1.34, nll=-1.51]\n",
      "Epoch 96: 100%|██████████| 142/142 [00:08<00:00, 16.63batch/s, kl=1.32, nll=-1.51]\n",
      "Epoch 97: 100%|██████████| 142/142 [00:08<00:00, 16.61batch/s, kl=1.31, nll=-1.51]\n",
      "Epoch 1: 100%|██████████| 130/130 [01:49<00:00,  1.18batch/s, kl=55.9, nll=80.7]\n",
      "Epoch 2: 100%|██████████| 130/130 [00:07<00:00, 16.42batch/s, kl=54.7, nll=1.43]\n",
      "Epoch 3: 100%|██████████| 130/130 [00:07<00:00, 16.54batch/s, kl=53.4, nll=0.0774]\n",
      "Epoch 4: 100%|██████████| 130/130 [00:07<00:00, 16.79batch/s, kl=52.1, nll=-.465] \n",
      "Epoch 5: 100%|██████████| 130/130 [00:07<00:00, 16.55batch/s, kl=50.7, nll=-.738]\n",
      "Epoch 6: 100%|██████████| 130/130 [00:07<00:00, 16.76batch/s, kl=49.3, nll=-.919]\n",
      "Epoch 7: 100%|██████████| 130/130 [00:07<00:00, 16.72batch/s, kl=47.9, nll=-1.04]\n",
      "Epoch 8: 100%|██████████| 130/130 [00:07<00:00, 16.76batch/s, kl=46.5, nll=-1.12]\n",
      "Epoch 9: 100%|██████████| 130/130 [00:07<00:00, 16.75batch/s, kl=45, nll=-1.19]  \n",
      "Epoch 10: 100%|██████████| 130/130 [00:07<00:00, 16.67batch/s, kl=43.6, nll=-1.23]\n",
      "Epoch 11: 100%|██████████| 130/130 [00:07<00:00, 16.86batch/s, kl=42.1, nll=-1.27]\n",
      "Epoch 12: 100%|██████████| 130/130 [00:07<00:00, 16.49batch/s, kl=40.7, nll=-1.3] \n",
      "Epoch 13: 100%|██████████| 130/130 [00:07<00:00, 16.77batch/s, kl=39.3, nll=-1.31]\n",
      "Epoch 14: 100%|██████████| 130/130 [00:07<00:00, 16.68batch/s, kl=37.8, nll=-1.33]\n",
      "Epoch 15: 100%|██████████| 130/130 [00:07<00:00, 16.71batch/s, kl=36.4, nll=-1.34]\n",
      "Epoch 16: 100%|██████████| 130/130 [00:07<00:00, 16.73batch/s, kl=35, nll=-1.35]  \n",
      "Epoch 17: 100%|██████████| 130/130 [00:07<00:00, 16.84batch/s, kl=33.6, nll=-1.35]\n",
      "Epoch 18: 100%|██████████| 130/130 [00:07<00:00, 16.80batch/s, kl=32.2, nll=-1.35]\n",
      "Epoch 19: 100%|██████████| 130/130 [00:07<00:00, 16.64batch/s, kl=30.8, nll=-1.35]\n",
      "Epoch 20: 100%|██████████| 130/130 [00:07<00:00, 16.45batch/s, kl=29.3, nll=-1.34]\n",
      "Epoch 21: 100%|██████████| 130/130 [00:07<00:00, 16.61batch/s, kl=27.9, nll=-1.34]\n",
      "Epoch 22: 100%|██████████| 130/130 [00:07<00:00, 16.54batch/s, kl=26.5, nll=-1.33]\n",
      "Epoch 23: 100%|██████████| 130/130 [00:07<00:00, 16.93batch/s, kl=25.1, nll=-1.32]\n",
      "Epoch 24: 100%|██████████| 130/130 [00:07<00:00, 16.60batch/s, kl=23.7, nll=-1.32]\n",
      "Epoch 25: 100%|██████████| 130/130 [00:07<00:00, 16.60batch/s, kl=22.2, nll=-1.31]\n",
      "Epoch 26: 100%|██████████| 130/130 [00:07<00:00, 16.69batch/s, kl=20.8, nll=-1.31]\n",
      "Epoch 27: 100%|██████████| 130/130 [00:07<00:00, 16.66batch/s, kl=19.4, nll=-1.3] \n",
      "Epoch 28: 100%|██████████| 130/130 [00:07<00:00, 16.64batch/s, kl=18, nll=-1.31]  \n",
      "Epoch 29: 100%|██████████| 130/130 [00:07<00:00, 16.83batch/s, kl=16.6, nll=-1.3] \n",
      "Epoch 30: 100%|██████████| 130/130 [00:07<00:00, 16.86batch/s, kl=15.3, nll=-1.31]\n",
      "Epoch 31: 100%|██████████| 130/130 [00:07<00:00, 16.53batch/s, kl=14, nll=-1.31]  \n",
      "Epoch 32: 100%|██████████| 130/130 [00:07<00:00, 16.72batch/s, kl=12.8, nll=-1.33]\n",
      "Epoch 33: 100%|██████████| 130/130 [00:07<00:00, 16.72batch/s, kl=11.7, nll=-1.33]\n",
      "Epoch 34: 100%|██████████| 130/130 [00:07<00:00, 16.70batch/s, kl=10.6, nll=-1.35]\n",
      "Epoch 35: 100%|██████████| 130/130 [00:07<00:00, 16.69batch/s, kl=9.67, nll=-1.36]\n",
      "Epoch 36: 100%|██████████| 130/130 [00:07<00:00, 16.70batch/s, kl=8.83, nll=-1.37]\n",
      "Epoch 37: 100%|██████████| 130/130 [00:07<00:00, 16.67batch/s, kl=8.1, nll=-1.36] \n",
      "Epoch 38: 100%|██████████| 130/130 [00:07<00:00, 16.58batch/s, kl=7.46, nll=-1.38]\n",
      "Epoch 39: 100%|██████████| 130/130 [00:07<00:00, 16.54batch/s, kl=6.91, nll=-1.38]\n",
      "Epoch 40: 100%|██████████| 130/130 [00:07<00:00, 16.66batch/s, kl=6.44, nll=-1.39]\n",
      "Epoch 41: 100%|██████████| 130/130 [00:07<00:00, 16.48batch/s, kl=6.04, nll=-1.39]\n",
      "Epoch 42: 100%|██████████| 130/130 [00:07<00:00, 16.55batch/s, kl=5.7, nll=-1.39] \n",
      "Epoch 43: 100%|██████████| 130/130 [00:07<00:00, 16.86batch/s, kl=5.41, nll=-1.39]\n",
      "Epoch 44: 100%|██████████| 130/130 [00:07<00:00, 16.62batch/s, kl=5.16, nll=-1.39]\n",
      "Epoch 45: 100%|██████████| 130/130 [00:07<00:00, 16.74batch/s, kl=4.94, nll=-1.4] \n",
      "Epoch 46: 100%|██████████| 130/130 [00:07<00:00, 16.86batch/s, kl=4.74, nll=-1.4] \n",
      "Epoch 47: 100%|██████████| 130/130 [00:07<00:00, 16.56batch/s, kl=4.57, nll=-1.4] \n",
      "Epoch 48: 100%|██████████| 130/130 [00:07<00:00, 16.55batch/s, kl=4.41, nll=-1.4] \n",
      "Epoch 49: 100%|██████████| 130/130 [00:07<00:00, 16.71batch/s, kl=4.25, nll=-1.4] \n",
      "Epoch 50: 100%|██████████| 130/130 [00:07<00:00, 16.61batch/s, kl=4.11, nll=-1.41]\n",
      "Epoch 51: 100%|██████████| 130/130 [00:07<00:00, 16.72batch/s, kl=3.98, nll=-1.41]\n",
      "Epoch 52: 100%|██████████| 130/130 [00:07<00:00, 16.81batch/s, kl=3.85, nll=-1.41]\n",
      "Epoch 53: 100%|██████████| 130/130 [00:07<00:00, 16.39batch/s, kl=3.72, nll=-1.42]\n",
      "Epoch 54: 100%|██████████| 130/130 [00:07<00:00, 16.59batch/s, kl=3.61, nll=-1.42]\n",
      "Epoch 55: 100%|██████████| 130/130 [00:07<00:00, 16.43batch/s, kl=3.5, nll=-1.42] \n",
      "Epoch 56: 100%|██████████| 130/130 [00:07<00:00, 16.56batch/s, kl=3.4, nll=-1.43] \n",
      "Epoch 57: 100%|██████████| 130/130 [00:07<00:00, 16.51batch/s, kl=3.29, nll=-1.42]\n",
      "Epoch 58: 100%|██████████| 130/130 [00:07<00:00, 16.49batch/s, kl=3.2, nll=-1.43] \n",
      "Epoch 59: 100%|██████████| 130/130 [00:07<00:00, 16.58batch/s, kl=3.1, nll=-1.42] \n",
      "Epoch 60: 100%|██████████| 130/130 [00:07<00:00, 16.58batch/s, kl=3.01, nll=-1.44]\n",
      "Epoch 61: 100%|██████████| 130/130 [00:07<00:00, 16.64batch/s, kl=2.92, nll=-1.43]\n",
      "Epoch 62: 100%|██████████| 130/130 [00:07<00:00, 16.82batch/s, kl=2.84, nll=-1.44]\n",
      "Epoch 63: 100%|██████████| 130/130 [00:07<00:00, 16.66batch/s, kl=2.77, nll=-1.44]\n",
      "Epoch 64: 100%|██████████| 130/130 [00:07<00:00, 16.66batch/s, kl=2.69, nll=-1.44]\n",
      "Epoch 65: 100%|██████████| 130/130 [00:07<00:00, 16.72batch/s, kl=2.62, nll=-1.44]\n",
      "Epoch 66: 100%|██████████| 130/130 [00:07<00:00, 16.78batch/s, kl=2.55, nll=-1.44]\n",
      "Epoch 67: 100%|██████████| 130/130 [00:07<00:00, 16.56batch/s, kl=2.48, nll=-1.45]\n",
      "Epoch 68: 100%|██████████| 130/130 [00:07<00:00, 16.66batch/s, kl=2.42, nll=-1.45]\n",
      "Epoch 69: 100%|██████████| 130/130 [00:07<00:00, 16.63batch/s, kl=2.36, nll=-1.45]\n",
      "Epoch 70: 100%|██████████| 130/130 [00:07<00:00, 16.78batch/s, kl=2.3, nll=-1.45] \n",
      "Epoch 71: 100%|██████████| 130/130 [00:07<00:00, 16.52batch/s, kl=2.25, nll=-1.45]\n",
      "Epoch 72: 100%|██████████| 130/130 [00:07<00:00, 16.68batch/s, kl=2.19, nll=-1.45]\n",
      "Epoch 73: 100%|██████████| 130/130 [00:07<00:00, 16.65batch/s, kl=2.14, nll=-1.46]\n",
      "Epoch 74: 100%|██████████| 130/130 [00:07<00:00, 16.62batch/s, kl=2.09, nll=-1.46]\n",
      "Epoch 75: 100%|██████████| 130/130 [00:07<00:00, 16.45batch/s, kl=2.05, nll=-1.46]\n",
      "Epoch 76: 100%|██████████| 130/130 [00:07<00:00, 16.52batch/s, kl=2, nll=-1.46]   \n",
      "Epoch 77: 100%|██████████| 130/130 [00:07<00:00, 16.43batch/s, kl=1.96, nll=-1.46]\n",
      "Epoch 78: 100%|██████████| 130/130 [00:07<00:00, 16.68batch/s, kl=1.92, nll=-1.47]\n",
      "Epoch 79: 100%|██████████| 130/130 [00:07<00:00, 16.60batch/s, kl=1.88, nll=-1.47]\n",
      "Epoch 80: 100%|██████████| 130/130 [00:07<00:00, 16.58batch/s, kl=1.84, nll=-1.47]\n",
      "Epoch 81: 100%|██████████| 130/130 [00:07<00:00, 16.68batch/s, kl=1.8, nll=-1.47] \n",
      "Epoch 82: 100%|██████████| 130/130 [00:07<00:00, 16.61batch/s, kl=1.77, nll=-1.47]\n",
      "Epoch 83: 100%|██████████| 130/130 [00:07<00:00, 16.72batch/s, kl=1.74, nll=-1.47]\n",
      "Epoch 84: 100%|██████████| 130/130 [00:07<00:00, 16.75batch/s, kl=1.7, nll=-1.48] \n",
      "Epoch 85: 100%|██████████| 130/130 [00:07<00:00, 16.67batch/s, kl=1.67, nll=-1.48]\n",
      "Epoch 86: 100%|██████████| 130/130 [00:07<00:00, 16.83batch/s, kl=1.64, nll=-1.48]\n",
      "Epoch 87: 100%|██████████| 130/130 [00:07<00:00, 16.77batch/s, kl=1.61, nll=-1.48]\n",
      "Epoch 88: 100%|██████████| 130/130 [00:07<00:00, 16.81batch/s, kl=1.58, nll=-1.48]\n",
      "Epoch 89: 100%|██████████| 130/130 [00:07<00:00, 16.67batch/s, kl=1.56, nll=-1.48]\n",
      "Epoch 90: 100%|██████████| 130/130 [00:07<00:00, 16.68batch/s, kl=1.53, nll=-1.49]\n",
      "Epoch 91: 100%|██████████| 130/130 [00:07<00:00, 16.60batch/s, kl=1.51, nll=-1.48]\n",
      "Epoch 92: 100%|██████████| 130/130 [00:07<00:00, 16.59batch/s, kl=1.49, nll=-1.48]\n",
      "Epoch 93: 100%|██████████| 130/130 [00:07<00:00, 16.54batch/s, kl=1.47, nll=-1.49]\n",
      "Epoch 94: 100%|██████████| 130/130 [00:07<00:00, 16.70batch/s, kl=1.45, nll=-1.49]\n",
      "Epoch 95: 100%|██████████| 130/130 [00:07<00:00, 16.58batch/s, kl=1.43, nll=-1.49]\n",
      "Epoch 96: 100%|██████████| 130/130 [00:07<00:00, 16.75batch/s, kl=1.41, nll=-1.49]\n",
      "Epoch 97: 100%|██████████| 130/130 [00:07<00:00, 16.72batch/s, kl=1.39, nll=-1.49]\n",
      "Epoch 1:  23%|██▎       | 27/119 [01:08<00:18,  4.96batch/s, kl=56.4, nll=236] "
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from Test_Fn import Test_fn\n",
    "\n",
    "max_iter =250\n",
    "model = IRNN_Bayes\n",
    "gamma = 28\n",
    "root = 'Results/IRNN_Bayes/'\n",
    "\n",
    "n_folds = 4 # increase this to improve rubustness, will get slower\n",
    "eval = Eval_Fn(model=IRNN_Bayes, \n",
    "               root = root, gamma=gamma, plot=False, n_folds=n_folds, verbose=False)\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=eval,\n",
    "    pbounds=model.pbounds,\n",
    "    random_state=1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "optimizer = load_steps(root, optimizer)\n",
    "\n",
    "for _ in range(100):\n",
    "    optimizer.maximize(\n",
    "        init_points=10,\n",
    "        n_iter=10)\n",
    "\n",
    "    save_steps(root, optimizer)\n",
    "\n",
    "Test_fn(root = root, model = model, gammas=[gamma], test_seasons = [2015])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter =250\n",
    "model = IRNN_Bayes\n",
    "gamma = 28\n",
    "root = 'Results/IRNN_Bayes/'\n",
    "\n",
    "n_folds = 5 # increase this to improve rubustness, will get slower\n",
    "\n",
    "eval = Eval_Fn(model=IRNN_Bayes, root = root, gamma=gamma, plot=False, n_folds=n_folds, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(rnn_units = 25, \n",
    "     n_queries = 20,\n",
    "     kl_power = -2.,\n",
    "     p_scale_pwr = -3.,\n",
    "     q_scale_pwr = -3.,\n",
    "     op_scale_pwr = -3.,\n",
    "     epochs = 10,\n",
    "     lr_power = -3.,\n",
    "     q_scale = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pbounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    from bayes_opt import BayesianOptimization\n",
    "    from Test_Fn import Test_fn\n",
    "\n",
    "    max_iter =250\n",
    "    model = FF\n",
    "    gamma = 14\n",
    "    root = 'Results/FF/'\n",
    "\n",
    "    n_folds = 5 # increase this to improve rubustness, will get slower\n",
    "\n",
    "    eval = Eval_Fn(model=model, root = root, gamma=gamma, plot=False, n_folds=n_folds, verbose=False)\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=eval,\n",
    "        pbounds=model.pbounds,\n",
    "        random_state=1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    optimizer = load_steps(root, optimizer)\n",
    "\n",
    "    optimizer.maximize(\n",
    "        init_points=10,\n",
    "        n_iter=50)\n",
    "\n",
    "    save_steps(root, optimizer)\n",
    "\n",
    "    Test_fn(root = root, model = model, gammas=[gamma], test_seasons = [2015])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_std = 0.1\n",
    "c = np.log(np.expm1(1.))\n",
    "q_scale = prior_std\n",
    "\n",
    "x = np.random.normal(0, 0.1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = q_scale*tf.nn.softplus(c + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
